{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import data_io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = [\"AK\",\"AL\",\"AR\",\"AZ\",\"CA\",\"CO\",\"CT\",\"DC\",\"DE\",\"FL\",\"GA\",\n",
    "              \"HI\",\"IA\",\"ID\", \"IL\",\"IN\",\"KS\",\"KY\",\"LA\",\"MA\",\"MD\",\"ME\",\n",
    "              \"MI\",\"MN\",\"MO\",\"MS\",\"MT\",\"NC\",\"ND\",\"NE\",\"NH\",\n",
    "              \"NJ\",\"NM\",\"NV\",\"NY\", \"OH\",\"OK\",\"OR\",\"PA\",\n",
    "              \"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"UT\",\"VA\",\"VT\",\"WA\",\"WI\",\"WV\",\"WY\"]\n",
    "\n",
    "MIN_YEAR = 2019\n",
    "MAX_YEAR = 2021\n",
    "EXCEL_OPTIONS = {'strings_to_urls': False,\n",
    "                'strings_to_formulas': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_abbr_to_name = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isBlank (myString):\n",
    "    if myString and myString.strip():\n",
    "        #myString is not None AND myString is not empty or blank\n",
    "        return False\n",
    "    #myString is None OR myString is empty or blank\n",
    "    return True\n",
    "\n",
    "def remove_leading_whitespace(df, column):\n",
    "    new_series = pd.Series(len(df))\n",
    "    i = 0\n",
    "    for i in range(0, len(df)):\n",
    "        old_str = df.loc[i, column]\n",
    "        new_str = old_str.lstrip()\n",
    "        new_series[i] = new_str\n",
    "\n",
    "    return new_series\n",
    "\n",
    "def get_loc_string(test1):\n",
    "\n",
    "    test1 = test1.split('\\r\\n\\xa0 ')\n",
    "    test1 = test1[1]\n",
    "\n",
    "    i = 0\n",
    "    for i in range(0, len(test1) - 1):\n",
    "        if test1[i].isspace() and test1[i+1].isspace():\n",
    "            test1 = test1[0:i]\n",
    "            break\n",
    "    return test1\n",
    "\n",
    "def only_numerics(seq):\n",
    "    seq_type= type(seq)\n",
    "    return seq_type().join(filter(seq_type.isdigit, seq))\n",
    "\n",
    "def extract_year(x):\n",
    "    if type(x) != str:\n",
    "        return np.nan\n",
    "    else:\n",
    "        x = x.lower()\n",
    "    if x == 'none' or 'invalid date' in x or x == 'Created':\n",
    "        return np.nan\n",
    "    else:\n",
    "        #print(x[-4:])\n",
    "        try:\n",
    "            new_var = int(x[-4:])\n",
    "        except:\n",
    "            return np.nan\n",
    "        return new_var\n",
    "\n",
    "\n",
    "def extract_whole_date(x):\n",
    "    if type(x) != str or 'none' in x:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x[8:]\n",
    "\n",
    "\n",
    "def get_social(x):\n",
    "    if type(x) != str:\n",
    "        return x\n",
    "    x = x.lower()\n",
    "    if 'none' in x or pd.isnull(x):\n",
    "        return np.nan\n",
    "    if ',' in x:\n",
    "        x = x.replace(',', '')\n",
    "    if ' shares' in x:\n",
    "        x = x.replace(' shares', '')\n",
    "    if 'total' in x:\n",
    "        x = x[0:x.find('total')]\n",
    "        \n",
    "    if ' share' in x:\n",
    "        x = x.replace(' share', '')\n",
    "    if ' followers' in x:\n",
    "        x = x.replace(' followers', '')\n",
    "    if ' follower' in x:\n",
    "        x = x.replace(' follower', '')\n",
    "    if 'k' in x:\n",
    "        new = x[0:x.find('k')]\n",
    "        if '.' in new:\n",
    "            trail = '00'\n",
    "            new = new.replace('.', '')\n",
    "        else:\n",
    "            trail = '000'\n",
    "            \n",
    "        return new+trail\n",
    "    if 'friend' in x or 'comment' in x:\n",
    "        return np.nan\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def get_other_loc(x):\n",
    "    if type(x) != str or x == 'none':\n",
    "        return np.nan\n",
    "    if ',' in x:\n",
    "        split_str = x.split(',')\n",
    "        return split_str[0].lower()\n",
    "    else:\n",
    "        return x.lower()\n",
    "\n",
    "def get_state_var(x):\n",
    "    if x == 'none':\n",
    "        return np.nan\n",
    "\n",
    "    if type(x) == str:\n",
    "\n",
    "        if ',' in x:\n",
    "            new_list = x.split(',')\n",
    "            state_str = new_list[1]\n",
    "            if isBlank(state_str):\n",
    "                return np.nan\n",
    "            else:\n",
    "                return state_str.strip()\n",
    "        else:\n",
    "            return x[-2:]\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "def extract_deprecated_val(x):\n",
    "    if 'k' in x:\n",
    "        x = x[0:x.find('k')]\n",
    "        if '.' in x:\n",
    "            trail = '00'\n",
    "            x = x.replace('.', '')\n",
    "        else:\n",
    "            trail = '000'\n",
    "\n",
    "    elif 'm' in x:\n",
    "        x = x[0:x.find('m')]\n",
    "        if '.' in x:\n",
    "            trail = '00000'\n",
    "            x = x.replace('.', '')\n",
    "        else:\n",
    "            trail = '000000'\n",
    "    elif 'b' in x:\n",
    "        x = x[0:x.find('b')]\n",
    "        if '.' in x:\n",
    "            trail = '00000000'\n",
    "            x = x.replace('.', '')\n",
    "        else:\n",
    "            trail = '000000000'\n",
    "    goal = x+trail\n",
    "\n",
    "    goal = int(only_numerics(goal))\n",
    "    return goal\n",
    "\n",
    "\n",
    "def get_money_raised(x):\n",
    "    if type(x) != str or 'none' in x:\n",
    "        return np.nan\n",
    "    elif '%' in x:\n",
    "        return np.nan\n",
    "    elif '$' not in x:\n",
    "        return 'NOT USD'\n",
    "    else:\n",
    "        x = x.lower()\n",
    "        if 'of' in x:\n",
    "            new_info = x.split('of')\n",
    "            try:\n",
    "                if 'k' in new_info[0] or 'm' in new_info[0]:\n",
    "                    money_raised = extract_deprecated_val(new_info[0])\n",
    "                else:\n",
    "                    money_raised = int(only_numerics(new_info[0]))\n",
    "            except:\n",
    "                print('failed to get money raised: ', x)\n",
    "                money_raised = np.nan\n",
    "\n",
    "        elif 'raised' in x:\n",
    "            if 'goal' in x:\n",
    "                new = x.split('\\n')\n",
    "                this_str = new[0]\n",
    "                this_str = this_str[this_str.find('$'):]\n",
    "                if '.' in this_str:\n",
    "                    new = this_str[0:this_str.find('.')]\n",
    "                    if 'k' in new or 'm' in new:\n",
    "                        money_raised = extract_deprecated_val(new)\n",
    "                    else:\n",
    "                        money_raised = int(only_numerics(new))\n",
    "            else:\n",
    "                try:\n",
    "                    if 'k' in x or 'm' in x:\n",
    "                        money_raised = extract_deprecated_val(x)\n",
    "                    else:\n",
    "                        money_raised = int(only_numerics(x))\n",
    "                except:\n",
    "                    print('failed to get money raised: ', x)\n",
    "                    money_raised = np.nan\n",
    "\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "        return money_raised\n",
    "\n",
    "    \n",
    "def get_goal(x):\n",
    "    if type(x) != str:\n",
    "        return np.nan\n",
    "    if '%' in x:\n",
    "        return np.nan\n",
    "    if '$' not in x:\n",
    "        return 'NOT USD'\n",
    "    x = x.lower()\n",
    "    if 'raised' in x and 'of' not in x:\n",
    "        if 'goal' in x:\n",
    "            new = x.split('\\n')\n",
    "            new = new[1]\n",
    "            new = new[new.find('$'):]\n",
    "            if 'k' in new or 'm' in new or 'b' in new:\n",
    "                goal = extract_deprecated_val(new)\n",
    "\n",
    "            else:\n",
    "                if '.' in x:\n",
    "                    new = new[0:new.find('.')]\n",
    "                goal = int(only_numerics(new))\n",
    "            return goal\n",
    "\n",
    "        else:\n",
    "            return np.nan\n",
    "    else:\n",
    "        if 'of' in x:\n",
    "            new_info = x.split('of')\n",
    "            new = new_info[1]\n",
    "            if 'k' in new or 'm' in new or 'b' in new:\n",
    "                goal = extract_deprecated_val(new)\n",
    "            else:\n",
    "                if '.' in new:\n",
    "                    new = new[0:new.find('.')]\n",
    "                try:\n",
    "                    goal = int(only_numerics(new))\n",
    "                except:\n",
    "                    goal = 'failed'\n",
    "            return goal\n",
    "\n",
    "        elif 'goal' in x:\n",
    "            return int(only_numerics(x))\n",
    "        else:\n",
    "            print('failed to parse goal: ', x)\n",
    "            \n",
    "def get_num_contributors(x):\n",
    "\n",
    "    if type(x) == str and x != 'none':\n",
    "        x = x.lower()\n",
    "        if 'raised' in x and '$' not in x:\n",
    "            new = x.split('in')\n",
    "            if 'k' in new:\n",
    "                new = extract_deprecated_val(new)\n",
    "            else:\n",
    "                new = int(only_numerics(new[0]))\n",
    "            return new\n",
    "        elif 'donor' in x and 'day' not in x and 'month' not in x:\n",
    "            if 'k' in x:\n",
    "                new = extract_deprecated_val(x)\n",
    "            else:\n",
    "                new = int(only_numerics(x))\n",
    "            return new\n",
    "        elif 'people' in x or 'person' in x:\n",
    "            if 'by' in x:\n",
    "                str_split1 = x.split('by')\n",
    "                if 'in' in x:\n",
    "                    str_split2 = str_split1[1].split('in')\n",
    "                    new = str_split2[0]\n",
    "                    if 'k' in new:\n",
    "                        new = extract_deprecated_val(new)\n",
    "                    else:\n",
    "                        new = int(only_numerics(new))\n",
    "                    return new\n",
    "                else:\n",
    "                    new = str_split1[1]\n",
    "                    if 'k' in new:\n",
    "                        new = extract_deprecated_val(new)\n",
    "                    else:\n",
    "                        new = int(only_numerics(new))\n",
    "                    return new\n",
    "            else:\n",
    "                print(x)\n",
    "                return x\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def remove_non_loc_info(x):\n",
    "    if type(x) == str:\n",
    "        temp = x.lower()\n",
    "        if 'donations' in temp and ' 1 donation' not in temp:\n",
    "            #print('donations in x')\n",
    "            loc = temp.find('donations')\n",
    "            delete = loc+len('donations')\n",
    "            temp = temp[delete:]\n",
    "            #return new\n",
    "        if '1 donation' in temp:\n",
    "            #print('donation in x')\n",
    "            loc = temp.find('donation')\n",
    "            delete = loc+len('donation')\n",
    "            temp = temp[delete:]\n",
    "            #return new\n",
    "        if 'organizer' in temp:\n",
    "            #print('organizer in x')\n",
    "            loc = temp.find('organizer')\n",
    "            delete = loc+len('organizer')\n",
    "            temp = temp[delete:]\n",
    "\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex cleaning functions\n",
    "import re \n",
    "def contruct_goal_pattern():\n",
    "    rtypes = [] # (type of values returned (raise,goal,both) , notation that money is recorded in (US vs foreign))\n",
    "    rpatterns = []\n",
    "    rpatterns.append(r'(.*)raised of(.*)goal')\n",
    "    rpatterns.append(r'(.*)of(.*)goal')\n",
    "    rpatterns.append(r'(.*)of(.*)')\n",
    "    rpatterns.append(r'(.*)raised of(.*)target')\n",
    "    rpatterns.append(r'Raised:(.*)Goal:(.*)')\n",
    "    rtypes+=[['both','US']] * 5\n",
    "    \n",
    "    rpatterns.append(r'(.*)des Ziels von(.*)') # german\n",
    "    rpatterns.append(\n",
    "        r'(.*)sur un objectif de(.*)') # french\n",
    "    rpatterns.append(r'(.*)del objetivo de(.*)') # spanish\n",
    "    rpatterns.append(r'(.*)da meta de(.*)') # romanian\n",
    "    rpatterns.append(r'(.*)su(.*)raccolti') # italian\n",
    "    rpatterns.append(r'(.*)van het doel(.*)') # dutch\n",
    "    rtypes+=[['both','foreign']] * 6 \n",
    "\n",
    "    rpatterns.append(r'(.*)raised')\n",
    "    rtypes+=[['raised','US']]\n",
    "    \n",
    "    rpatterns.append(r'(.*)réunis') # french\n",
    "    rpatterns.append(r'(.*)gesammelt') # german\n",
    "    rpatterns.append(r'(.*)recaudados') # spanish\n",
    "    rpatterns.append(r'(.*)arrecadados') # portugese\n",
    "    rpatterns.append(r'(.*)raccolti') # italian\n",
    "    rtypes+=[['raised','foreign']]*5\n",
    "\n",
    "    rpatterns.append(r'(.*)goal')\n",
    "    rpatterns.append(r'(.*)target')\n",
    "    rtypes+=[['goal','US']]*2 \n",
    "    \n",
    "    rpatterns.append(r'Objectif\\s*:(.*)') # french\n",
    "    rpatterns.append(r'Objetivo\\s*:(.*)') #spanish\n",
    "    rpatterns.append(r'(.*)Ziel') # german\n",
    "    rpatterns.append(r'Meta de(.*)') #romanian\n",
    "    rpatterns.append(r'(.*)obiettivo') # italian\n",
    "    rtypes+=[['goal','foreign']]*5 \n",
    "    patterns_collection = pd.Series(rtypes, index=rpatterns, name='rtype')\n",
    "    return patterns_collection\n",
    "\n",
    "\n",
    "GOAL_PATTERNS = contruct_goal_pattern()\n",
    "\n",
    "_clean_whitespace = lambda x: re.sub(r'\\s+', ' ', x).strip()\n",
    "\n",
    "THOUNDSAND_PATTERN = re.compile(r'\\d+[,.]*\\d*.*[k]')\n",
    "MILLION_PATTERN = re.compile(r'\\d+[,.]*\\d*.*[m]')\n",
    "BILLION_PATTERN = re.compile(r'\\d+[,.]*\\d*.*[b]')\n",
    "MONEY_PATTERN = re.compile(r\"\"\"( #start of group0, this is the desired output\n",
    "                                \\d+ #start digit of money amount, mustbe followed by abbr, number or marker, nonwords or end of string\n",
    "                                ((?<=\\d)[,.]\\d+)*  #(group1) this is an optional group that only appears if markers are present\n",
    "                                ((?<=\\d)[kmbKMB](?=\\W|$)){0,1} #(group2)match thousand,mill,bill abbreviation if present but only if theres one of them\n",
    "                                )#close group0\n",
    "                            \"\"\",re.VERBOSE)\n",
    "_remove_whitespace_inside_money = lambda x: re.sub(r'(?<=\\d|[,.])\\s(?=\\d|[,.]|[kmbKMB](?=\\W|$))','',x)\n",
    "_extract_money_amount = lambda x: MONEY_PATTERN.findall(_remove_whitespace_inside_money(x))\n",
    "def _switch_markers_to_us_notation(amnt):\n",
    "    chars = []\n",
    "    for c in amnt:\n",
    "        if c == ',':\n",
    "            chars.append('.')\n",
    "        elif c == '.':\n",
    "            chars.append(',')\n",
    "        else:\n",
    "            chars.append(c)\n",
    "    return ''.join(chars)\n",
    "\n",
    "def parse_money_into_floats(x,us_notation=True,switch_retry=True):\n",
    "    out = {'amount':np.nan,'currency':np.nan}\n",
    "    if pd.isnull(x): return out\n",
    "    old_x = x\n",
    "    x = x.strip().lower()\n",
    "    if len(x) == 0: return out\n",
    "    try:\n",
    "        amnt = _extract_money_amount(x)[0][0]\n",
    "        curr = x.replace(amnt,'').strip()\n",
    "        if not us_notation:\n",
    "            # money amount written in foreign notation\n",
    "            # need to swap , and . \n",
    "            amnt = _switch_markers_to_us_notation(amnt)\n",
    "        numeric_amnt = ''.join(re.findall('\\d*|[,.]*', amnt))\n",
    "        numeric_amnt = float(numeric_amnt.replace(',', ''))\n",
    "        trail = 1\n",
    "        if THOUNDSAND_PATTERN.search(amnt):\n",
    "            trail = 1000\n",
    "        elif MILLION_PATTERN.search(amnt):\n",
    "            trail = 1000000\n",
    "        elif BILLION_PATTERN.search(amnt):\n",
    "            trail = 1000000000\n",
    "        out['amount']=numeric_amnt * trail\n",
    "        out['currency'] = curr\n",
    "        return out\n",
    "    except:\n",
    "        if switch_retry:\n",
    "            print(f'[WARNING] failed to parse {old_x} but will retry by swapping , and .')\n",
    "            # ~ doesnt work, have to be not \n",
    "            out = parse_money_into_floats(x,us_notation=not us_notation,switch_retry=False)\n",
    "            if not pd.isna([*out.values()]).all():\n",
    "                print('[WARNING] parsed results might be inaccurate, check below')\n",
    "                print(f\"[RETRY OUTPUT] original:{x}|parsed_amnt:{out['amount']}|parsed_currency:{out['currency']}\")\n",
    "        else:\n",
    "            print(f'failed to parse original x:{old_x}|stripped:{x}')\n",
    "        return out\n",
    "    \n",
    "def get_raised_and_goal_amount(x, USD_only=True):\n",
    "    import re\n",
    "    out = {\"raised\": np.nan, \"goal\": np.nan,\"raised_amnt\":np.nan,\n",
    "           \"raised_curr\":np.nan,\"goal_amnt\":np.nan,\"goal_curr\":np.nan}\n",
    "    if x == 'none': return out\n",
    "    if USD_only:\n",
    "        if '$' not in x: return out\n",
    "    x = _clean_whitespace(x)\n",
    "    for rpattern, rtype in GOAL_PATTERNS.iteritems():\n",
    "        results = re.findall(rpattern, x)\n",
    "        if len(results) > 0:\n",
    "            results = results[0]  # pop out results\n",
    "            rtype_value,rtype_notation = rtype[0],rtype[1]\n",
    "            if rtype_value == 'both':\n",
    "                out[\"raised\"], out[\"goal\"] = results[0], results[1]\n",
    "                for k in [\"raised\",\"goal\"]:\n",
    "                    results = parse_money_into_floats(out[k],us_notation=rtype_notation=='US')\n",
    "                    out[k+\"_amnt\"],out[k+\"_curr\"] = results[\"amount\"],results[\"currency\"]\n",
    "            elif rtype_value == \"raised\":\n",
    "                out[\"raised\"] = results\n",
    "                results = parse_money_into_floats(out[\"raised\"],us_notation=rtype_notation=='US')\n",
    "                out[\"raised_amnt\"],out[\"raised_curr\"] = results[\"amount\"],results[\"currency\"]\n",
    "            elif rtype_value == \"goal\":\n",
    "                out[\"goal\"] = results\n",
    "                results = parse_money_into_floats(out[\"goal\"],us_notation=rtype_notation=='US')\n",
    "                out[\"goal_amnt\"],out[\"goal_curr\"] = results[\"amount\"],results[\"currency\"]\n",
    "            break\n",
    "    if pd.isna([*out.values()]).all(): print(f'failed to parse {x}')\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def standardize_MBk_in_number_str(x):\n",
    "    if pd.isnull(x): return x\n",
    "    old_x = x\n",
    "    x = x.strip().lower()\n",
    "    if len(x) == 0: return np.nan\n",
    "    try:\n",
    "        x_i = re.findall('\\d+[,.]*\\d*', x)[0]\n",
    "        x_i = float(x_i.replace(',', ''))\n",
    "        trail = 1\n",
    "        if THOUNDSAND_PATTERN.search(x):\n",
    "            trail = 1000\n",
    "        elif MILLION_PATTERN.search(x):\n",
    "            trail = 1000000\n",
    "        elif BILLION_PATTERN.search(x):\n",
    "            trail = 1000000000\n",
    "        return x_i * trail\n",
    "    except:\n",
    "        print(f'original x:{old_x}|stripped:{x}')\n",
    "        return np.nan\n",
    "\n",
    "def contruct_date_pattern():\n",
    "    rpatterns = []\n",
    "    rtypes = []\n",
    "    rpatterns.append(r'Created ([a-zA-Z]+) (\\d+), (\\d+)')\n",
    "    rtypes.append(['month', 'day', 'year'])\n",
    "    rpatterns.append(r'Created (\\d+) ([a-zA-z]+) (\\d+)')\n",
    "    rtypes.append(['day', 'month', 'year'])\n",
    "    rpatterns.append(r'Created by .*?on ([a-zA-z]+) (\\d+), (\\d+)')\n",
    "    rtypes.append(['month', 'day', 'year'])\n",
    "    rpatterns.append(r'Erstellt am (\\d+). (\\S+) (\\d+)')\n",
    "    rtypes.append(['day', 'month', 'year'])\n",
    "    rpatterns.append(r'Date de création : (\\d+) (\\S+) (\\d+)')\n",
    "    rtypes.append(['day', 'month', 'year'])\n",
    "    rpatterns.append(r'Fecha de creación: (\\d+) de (\\S+) de (\\d+)')\n",
    "    rtypes.append(['day', 'month', 'year'])\n",
    "    rpatterns.append(r'Creata il (\\d+) (\\S+) (\\d+)')\n",
    "    rtypes.append(['day', 'month', 'year'])\n",
    "    rpatterns.append(r'Gemaakt op (\\d+) (\\S+) (\\d+)')\n",
    "    rtypes.append(['day', 'month', 'year'])\n",
    "    rpatterns.append(r'Criada em (\\d+) de (\\S+) de (\\d+)')\n",
    "    rtypes.append(['day', 'month', 'year'])\n",
    "    # special case: put this in day field for later processing with archive_timestamp\n",
    "    # double parenthesis to match regex findall output as other patterns\n",
    "    rpatterns.append(r'Created ((\\d+ days ago))')\n",
    "    rtypes.append(['day', 'day'])\n",
    "    return pd.Series(rtypes, index=rpatterns, name='rtype')\n",
    "\n",
    "DATE_PATTERNS = contruct_date_pattern()\n",
    "\n",
    "def parse_created_date(x):\n",
    "    out = {\"day\": np.nan, \"month\": np.nan, \"year\": np.nan}\n",
    "    if x == 'none': return out\n",
    "    x = _clean_whitespace(x)\n",
    "    if x.find('Invalid date') > -1: return out\n",
    "    if x == 'Created': return out\n",
    "    for rpattern, rtype in DATE_PATTERNS.iteritems():\n",
    "        results = re.findall(rpattern, x)\n",
    "        if len(results) > 0:\n",
    "            results = results[0]  # pop out results\n",
    "            for k, v in zip(rtype, results):\n",
    "                out[k] = v\n",
    "            break\n",
    "    if pd.isna([*out.values()]).all(): print(f'failed to parse {x}')\n",
    "    return out\n",
    "\n",
    "def construct_status_pattern():\n",
    "    rpatterns = []\n",
    "    rtypes = []\n",
    "    rpatterns.append(r'^(\\S+) donor$') # ^ and $ help make match the whole string\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'raised by (\\S+) donor in \\S+? duration')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'\\S+? raised by (\\S+) donor in \\S+? duration')\n",
    "    rtypes.append(['ndonor'])\n",
    "\n",
    "    rpatterns.append(r'campaign created .*?duration ago')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'^recent donor [(](\\S+)[)]$')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'goal reached!')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'campaign ended')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'only \\S+? duration left to reach goal!')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'be the first to like this donor \\S+? duration ago')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'\\S+? donor likes this donor \\S+? duration ago')\n",
    "    rtypes.append([])\n",
    "\n",
    "    rpatterns.append(r'gesammelt von (\\S+) donore{0,1}n{0,1} in \\S+? tage{0,1}n{0,1}')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'gesammelt von (\\S+) donore{0,1}n{0,1} in \\S+? monate{0,1}')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'gesammelt von (\\S+) donore{0,1}n{0,1} in \\S+? stunde{0,1}n{0,1}')\n",
    "    rtypes.append(['ndonor'])\n",
    "\n",
    "    rpatterns.append(r'(\\S+) donornes ont fait un don en \\S+? mois{0,1}')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'(\\S+) donorne a fait un don en \\S+? mois{0,1}')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'(\\S+) donornes ont fait un don en \\S+? jours{0,1}')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'(\\S+) donorne a fait un don en \\S+? jours{0,1}')\n",
    "    rtypes.append(['ndonor'])\n",
    "\n",
    "    rpatterns.append(r'recaudados de (\\S+) donoras en \\S+? mese{0,1}s{0,1}')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'recaudados de (\\S+) donoras en \\S+? días{0,1}')\n",
    "    rtypes.append(['ndonor'])\n",
    "\n",
    "    rpatterns.append(r'recolectados de (\\S+) donoras{0,1} en \\S+? días{0,1}')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'recolectados de (\\S+) donoras{0,1} en \\S+? mese{0,1}s{0,1}')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'recolectados de (\\S+) donoras{0,1} en \\S+? horas{0,1}')\n",
    "    rtypes.append(['ndonor'])\n",
    "\n",
    "\n",
    "    rpatterns.append(r'donati da (\\S+) donor[ae] in \\S+? mesi')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'donati da (\\S+) donor[ae] in \\S+? ore')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'donati da (\\S+) donor[ae] in \\S+? giorni')\n",
    "    rtypes.append(['ndonor'])\n",
    "\n",
    "    rpatterns.append(r'arrecadados por (\\S+) pessoas em \\S+? meses')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'arrecadados por (\\S+) pessoas em \\S+? dias')\n",
    "    rtypes.append(['ndonor'])\n",
    "\n",
    "\n",
    "    rpatterns.append(r'not launched yet!')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'campagne créée depuis \\S+? mois')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'kampagne vor \\S+? monate erstellt')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'campagna creata \\S+? giorni fa')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'la campaña se creó hace \\S+? días')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'ingezameld door (\\S+) donoren binnen \\S+? maanden')\n",
    "    rtypes.append(['ndonor'])\n",
    "\n",
    "\n",
    "    rpatterns.append(r'la campaña se creó hace \\S+? mese{0,1}s{0,1}')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'kampagne vor \\S+? monate{0,1} erstellt')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'kampagne vor \\S+? tage{0,1}n{0,1} erstellt')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'campanha criada \\S+? dias atrás')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'ingezameld door (\\S+) donoren binnen \\S+? dagen')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'la campaña se creó hace \\S+? horas{0,1}')\n",
    "    rtypes.append([])\n",
    "    rpatterns.append(r'(\\S+) donorne a fait un don en \\S+? mois{0,1}')\n",
    "    rtypes.append(['ndonor'])\n",
    "    rpatterns.append(r'campagne créée depuis \\S+? jours{0,1}')\n",
    "    rtypes.append([])\n",
    "\n",
    "    rpatterns.append(r'recaudados de (\\S+) donoras en \\S+ días')\n",
    "    rtypes.append(['ndonor'])\n",
    "    \n",
    "    return pd.Series(rtypes, index=rpatterns, name='rtype')\n",
    "\n",
    "\n",
    "\n",
    "STATUS_PATTERNS = construct_status_pattern()\n",
    "\n",
    "\n",
    "def parse_status(x):\n",
    "    out = {'ndonor': np.nan}\n",
    "    if x == 'none': return out\n",
    "    if str(x).isnumeric(): \n",
    "        out['ndonor'] = x\n",
    "        return out\n",
    "    parsed = False\n",
    "    for rpattern, rtype in STATUS_PATTERNS.iteritems():\n",
    "        results = re.findall(rpattern, x)\n",
    "        if len(results) > 0:\n",
    "            for k, v in zip(rtype, results):\n",
    "                out[k] = v\n",
    "            parsed = True\n",
    "            break\n",
    "    if (not parsed) & pd.isna([*out.values()]).all():\n",
    "        print(f'failed to parse {x}')\n",
    "    return out\n",
    "\n",
    "# remove period at end, lowercase everything, clean whitespace characters\n",
    "_reformat_status = lambda x: _clean_whitespace(x[:-1].lower() if x[-1]=='.' else x.lower())\n",
    "# replace variation of units with standard words\n",
    "_duration_regex = re.compile(r'months*|days*|mins*|hours*')\n",
    "_donor_regex = re.compile(r'people|person|donors*|donations*|supporters*')\n",
    "_standardize_nouns = lambda x: _donor_regex.sub('donor',_duration_regex.sub('duration',x))\n",
    "# piece it all together\n",
    "standardize_status = lambda x: _standardize_nouns(_reformat_status(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_weird_title_type_pattern():\n",
    "    rpatterns=[]\n",
    "    rtypes=[]\n",
    "    rpatterns.append(r'^Page Not Found$')\n",
    "    rpatterns.append(r'^Unknown Error$')\n",
    "    rpatterns.append(r'^502 Bad Gateway$')\n",
    "    rpatterns.append(r'^404 Not Found$')\n",
    "    rpatterns.append(r'^403 Forbidden$')\n",
    "    rtypes += ['error']*5\n",
    "\n",
    "    rpatterns.append(r'^none$')\n",
    "    rtypes+= ['missing']\n",
    "\n",
    "    # gfm logistic\n",
    "    rpatterns.append(r'- Local Widget Builder$')\n",
    "    rpatterns.append(r'(.*)GoFundMe Support$')\n",
    "    rtypes += ['logistic']*2\n",
    "\n",
    "    # general home pages\n",
    "    rpatterns.append(r'^GoFundMe, le 1er site de crowdfunding pour créer une cagnotte en ligne$')\n",
    "    rpatterns.append(r'^GoFundMe : la plateforme gratuite n°1 de la collecte de fonds$')\n",
    "    rpatterns.append(r'^GoFundMe, le site n°1 de financement participatif et de collecte de fonds en ligne sans frais de plateforme$')\n",
    "    rpatterns.append(r'^Donate Online [|] Make Online Donations to People You Know!$')\n",
    "    rpatterns.append(r'^GoFundMe: Top-Website für Crowdfunding und Fundraising$')\n",
    "    rpatterns.append(r'^GoFundMe – die weltgrößte Crowdfunding-Seite zum Spendensammeln$')\n",
    "    rpatterns.append(r'^Funding(.*)[|] Fundraising - GoFundMe$')\n",
    "    rpatterns.append(r'^Raise Money For (.*?)[|](.*?)Fundraising - GoFundMe$')\n",
    "    rpatterns.append(r'^Personal & Charity Online Fundraising Websites that WORK!$')\n",
    "    rpatterns.append(r'(.*?)Fundraising - Start a Free Fundraiser$')\n",
    "    rpatterns.append(r'^Fundraising für (.*?)[|] Sammle Geld für(.*?)[|] GoFundMe$')\n",
    "    rpatterns.append(r'^Top Crowdfunding-Seite zum Spendensammeln – GoFundMe$')\n",
    "    rpatterns.append(r'^Personal Online Fundraising Websites that Work[!]$')\n",
    "    rpatterns.append(r'^Raise Money for YOU!(.*)!')\n",
    "    rpatterns.append(r'^GoFundMe:(.*)1')\n",
    "    rpatterns.append(r'^Raise money for your(.*?)Ideas!$')\n",
    "    rpatterns.append(r'^Raise Money for(.*)[|] GoFundMe$')\n",
    "    rpatterns.append(r'^Fundraising Ideas for(.*)')\n",
    "    rpatterns.append(r'(.*)Fundraising [|] Raise Money for(.*)[|] GoFundMe$')\n",
    "    rpatterns.append(r'(.*)Fundraising: Raise Money for (.*)')\n",
    "    rpatterns.append(r'(.*)Fundraising [|] Crowdfunding for(.*)– Free at GoFundMe$')\n",
    "    rpatterns.append(r'^Fundraising Ideas for(.*)')\n",
    "    rpatterns.append(r'^Find success with these Creative Fundraising Idea$')\n",
    "    rpatterns.append(r'^(.*)Fundraising [|] Fundraiser - GoFundMe[!]$')\n",
    "    rtypes+=['homepage']*24\n",
    "    return pd.Series(rtypes, index=rpatterns, name='rtype')\n",
    "WEIRD_TITLE_TYPE_PATTERNS = construct_weird_title_type_pattern()\n",
    "\n",
    "def detect_weird_title_type(x):\n",
    "    out = {'type':np.nan}\n",
    "    for rpattern, rtype in WEIRD_TITLE_TYPE_PATTERNS.iteritems():\n",
    "        if re.search(rpattern,x):\n",
    "            out['type'] = rtype\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def construct_title_pattern():\n",
    "    rpatterns =[]\n",
    "    rtypes=[]\n",
    "    rpatterns.append(r'^Fundraiser by(.*?):(.*)')\n",
    "    rtypes.append(['organizer','campaign_title'])\n",
    "    rpatterns.append(r'(.*)by(.*)- GoFundMe$')\n",
    "    rtypes.append(['campaign_title','organizer'])\n",
    "    rpatterns.append(r'^Fundraiser for(.*?)by(.*?):(.*)')\n",
    "    rtypes.append(['benefiter','organizer','campaign_title'])\n",
    "    rpatterns.append(r'^Collecte de fonds pour(.*?)organisée par(.*?):(.*)')\n",
    "    rtypes.append(['benefiter','organizer','campaign_title'])\n",
    "    rpatterns.append(r'^Spendenkampagne von(.*?)für(.*?):(.*)')\n",
    "    rtypes.append(['organizer','benefiter','campaign_title'])\n",
    "    rpatterns.append(r'^Campanha de arrecadação de fundos para(.*?)por(.*?):(.*)')\n",
    "    rtypes.append(['organizer','benefiter','campaign_title'])\n",
    "    rpatterns.append(r'^Campaña de(.*?):(.*)')\n",
    "    rtypes.append(['organizer','campaign_title'])\n",
    "    rpatterns.append(r'^Campanha de arrecadação de fundos de (.*?):(.*)')\n",
    "    rtypes.append(['organizer','campaign_title'])\n",
    "    rpatterns.append(r'^Cagnotte organisée par(.*?):(.*)')\n",
    "    rtypes.append(['organizer','campaign_title'])\n",
    "    rpatterns.append(r'^Spendenkampagne von(.*?):(.*)')\n",
    "    rtypes.append(['organizer','campaign_title'])\n",
    "    rpatterns.append(r'^Collecte de fonds organisée par(.*?):(.*)')\n",
    "    rtypes.append(['organizer','campaign_title'])\n",
    "    rpatterns.append(r'^Inzamelingsactie van(.*?):(.*)')\n",
    "    rtypes.append(['organizer','campaign_title'])\n",
    "    rpatterns.append(r'^Raccolta fondi di(.*?):(.*)')\n",
    "    rtypes.append(['organizer','campaign_title'])\n",
    "    rpatterns.append(r'^Cagnotte pour(.*?)organisée par(.*?):(.*)')\n",
    "    rtypes.append(['benefiter','organizer','campaign_title'])\n",
    "    rpatterns.append(r'^Inzamelingsactie voor(.*?)van(.*?):(.*)')\n",
    "    rtypes.append(['benefiter','organizer','campaign_title'])\n",
    "    return pd.Series(rtypes, index=rpatterns, name='rtype')\n",
    "TITLE_PATTERNS = construct_title_pattern()\n",
    "\n",
    "_remove_newline = lambda x: ' '.join(x.split()).strip()\n",
    "def parse_title(x):\n",
    "    out = {'benefiter': np.nan,'organizer':np.nan,'campaign_title':np.nan,'campaign_title_type':np.nan}\n",
    "    if x == 'none': return out\n",
    "    parsed = False\n",
    "    x = _remove_newline(x)\n",
    "    out['campaign_title_type'] = detect_weird_title_type(x)['type']\n",
    "    if not pd.isnull(out['campaign_title_type']): \n",
    "        return out\n",
    "    else:\n",
    "        out['campaign_title_type'] = 'campaign'\n",
    "    for rpattern, rtype in TITLE_PATTERNS.iteritems():\n",
    "        results = re.findall(rpattern, x)\n",
    "        if len(results) > 0:\n",
    "            results=results[0]\n",
    "            for k, v in zip(rtype, results):\n",
    "                out[k] = v.strip()\n",
    "            parsed = True\n",
    "            break\n",
    "    if not parsed:\n",
    "        out['campaign_title'] = x\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_is_valid(x):\n",
    "    if type(x) != str:\n",
    "        return False\n",
    "    if x not in state_list:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "#searches for determinig whether campaign mentions cancer\n",
    "SEARCHES = pd.read_csv(data_io.gfm/'gfm'/'cancer_search_terms.csv', encoding='utf-8')\n",
    "CANCER_SEARCHES = SEARCHES['cancer_type'].to_list()\n",
    "\n",
    "\n",
    "def find_cancer_story_title(story, title):\n",
    "    \n",
    "    story_truth = True if type(story) == str else False\n",
    "    title_truth = True if type(title) == str else False\n",
    "\n",
    "    if story_truth == False and title_truth == False:\n",
    "        return False\n",
    "    else:\n",
    "        new_story = story.lower() if story_truth == True else 'bad'\n",
    "        new_title = title.lower() if title_truth == True else 'bad'\n",
    "        if any(i in new_story for i in CANCER_SEARCHES):\n",
    "            return True\n",
    "        if any(i in new_title for i in CANCER_SEARCHES):\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def cancer_in_x(x):\n",
    "    if type(x) == str:\n",
    "        x = x.lower()\n",
    "        if any(i in x for i in CANCER_SEARCHES):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "def immunotherapy_mention(x):\n",
    "    if type(x) == str:\n",
    "        if 'immunotherap' in x or 'immuno therap' in x:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def is_english(x):\n",
    "    if type(x) == str:\n",
    "        x = x.lower()\n",
    "        if 'des ziels' in x:\n",
    "            return False\n",
    "        elif 'gesammelt' in x:\n",
    "            return False\n",
    "        elif 'recolectados' in x:\n",
    "            return False\n",
    "        elif 'del objetivo' in x:\n",
    "            return False\n",
    "        elif 'da meta de' in x:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "        \n",
    "def tag_is_valid(x):\n",
    "    tag = x.lower()\n",
    "    if 'medical' in tag:\n",
    "        return True\n",
    "    elif 'emergenc' in tag:\n",
    "        return True\n",
    "    elif 'family' in tag:\n",
    "        return True\n",
    "    elif 'community' in tag:\n",
    "        return True\n",
    "    elif 'other' in tag:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def assign_new_tag(x):\n",
    "    tag = x.lower()\n",
    "    if 'medical' in tag:\n",
    "        return 'medical'\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "def medical_in_tag(x):\n",
    "    if type(x) == str:\n",
    "        if 'medical' in x:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "def check_for_spain(x, currency):\n",
    "    if type(currency)== str:\n",
    "        if currency == 'NOT USD':\n",
    "            if type(x) == str:\n",
    "                x = x.lower()\n",
    "                if 'ct, spain' in x or ('barcelona' in x and 'spain' in x):\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read in master dataframe and set up exclusion tracker\n",
    "\n",
    "Master dataframe is generated by Make master tables.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_DF = pd.read_csv(data_io.input_raw/'scrape_output'/'all_output_no_duplicate.csv', \n",
    "                        encoding='utf-8', sep='|', index_col=[0], dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'url', 'last_donation_time', 'last_update_time',\n",
       "       'created_date', 'location_city', 'location_country',\n",
       "       'location_stateprefix', 'poster', 'story', 'title', 'goal',\n",
       "       'raised_amnt', 'goal_amnt', 'currency', 'tag', 'num_donors',\n",
       "       'num_likes', 'num_shares', 'charity_details', 'day', 'month', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MASTER_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy to be double sure you don't change master\n",
    "df = MASTER_DF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050841, 23) (29477, 23)\n"
     ]
    }
   ],
   "source": [
    "# the really good scrape used window.initialState info and have standardized timestamps already for created_date\n",
    "created_date_ts = pd.to_datetime(df.created_date, errors='coerce')\n",
    "df_good_scrape_bool = created_date_ts.notna()\n",
    "\n",
    "# save these seperately cause we don't have to process them \n",
    "df_good_scrape = df[df_good_scrape_bool]\n",
    "df =  df[~df_good_scrape_bool]\n",
    "# dfs_all_decent are the ones we need to parse out information from\n",
    "print(df_good_scrape.shape,df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Parse variables using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_tqdm= True\n",
    "if use_tqdm: from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse out title for benefiter, organizer, and campaign_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing title:   0%|          | 1/29477 [00:00<01:57, 250.32it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-4faac59d8797>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Parsing title'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtitle_parsed_dicts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtitle_parsed_dicts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs109a/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs109a/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs109a/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cancer-crowdfunding-explorer/notebooks/utils.py\u001b[0m in \u001b[0;36mparse_title\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_remove_newline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'campaign_title_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_weird_title_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'campaign_title_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cancer-crowdfunding-explorer/notebooks/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0mTITLE_PATTERNS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_title_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m \u001b[0m_remove_newline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'benefiter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'organizer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'campaign_title'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'campaign_title_type'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "if use_tqdm: \n",
    "    tqdm.pandas(desc='Parsing title')\n",
    "    title_parsed_dicts=df.title.progress_apply(utils.parse_title)\n",
    "else:\n",
    "    title_parsed_dicts=df.title.apply(utils.parse_title)\n",
    "title_parsed_df=pd.DataFrame.from_records(title_parsed_dicts,index=title_parsed_dicts.index)\n",
    "title_parsed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join parsed results into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both          1777203\n",
      "right_only          0\n",
      "left_only           0\n",
      "Name: _merge, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "parsed_cols = ['benefiter','organizer','campaign_title','campaign_title_type']\n",
    "df.drop(columns=parsed_cols,errors='ignore',inplace=True)\n",
    "df = df.merge(title_parsed_df[parsed_cols],on='campaign_id',how='left',indicator=True)\n",
    "# See merge results\n",
    "print(df._merge.value_counts())\n",
    "df.drop(columns='_merge',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>benefiter</th>\n",
       "      <th>organizer</th>\n",
       "      <th>campaign_title</th>\n",
       "      <th>campaign_title_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10u3c</th>\n",
       "      <td>Fundraiser by Chris D'Angelo : In Memory of Mike</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chris D'Angelo</td>\n",
       "      <td>In Memory of Mike</td>\n",
       "      <td>campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10v10</th>\n",
       "      <td>Fundraiser by Marie Espinal : The Church of Na...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marie Espinal</td>\n",
       "      <td>The Church of Naranjo Dulce</td>\n",
       "      <td>campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10xis</th>\n",
       "      <td>DiseaseFreedom is a Fraud! Leisa Dargis is a P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leisa Dargis</td>\n",
       "      <td>DiseaseFreedom is a Fraud! Leisa Dargis is a P...</td>\n",
       "      <td>campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ipyu0</th>\n",
       "      <td>Raise Money for YOU! Crowdfunding &amp; Online Fun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>homepage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ziaqw</th>\n",
       "      <td>Raise Money for YOU! Crowdfunding &amp; Online Fun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>homepage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31qeuw</th>\n",
       "      <td>Raise Money for YOU! Crowdfunding &amp; Online Fun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>homepage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         title benefiter  \\\n",
       "campaign_id                                                                \n",
       "10u3c         Fundraiser by Chris D'Angelo : In Memory of Mike       NaN   \n",
       "10v10        Fundraiser by Marie Espinal : The Church of Na...       NaN   \n",
       "10xis        DiseaseFreedom is a Fraud! Leisa Dargis is a P...       NaN   \n",
       "1ipyu0       Raise Money for YOU! Crowdfunding & Online Fun...       NaN   \n",
       "2ziaqw       Raise Money for YOU! Crowdfunding & Online Fun...       NaN   \n",
       "31qeuw       Raise Money for YOU! Crowdfunding & Online Fun...       NaN   \n",
       "\n",
       "                  organizer  \\\n",
       "campaign_id                   \n",
       "10u3c        Chris D'Angelo   \n",
       "10v10         Marie Espinal   \n",
       "10xis          Leisa Dargis   \n",
       "1ipyu0                  NaN   \n",
       "2ziaqw                  NaN   \n",
       "31qeuw                  NaN   \n",
       "\n",
       "                                                campaign_title  \\\n",
       "campaign_id                                                      \n",
       "10u3c                                        In Memory of Mike   \n",
       "10v10                              The Church of Naranjo Dulce   \n",
       "10xis        DiseaseFreedom is a Fraud! Leisa Dargis is a P...   \n",
       "1ipyu0                                                     NaN   \n",
       "2ziaqw                                                     NaN   \n",
       "31qeuw                                                     NaN   \n",
       "\n",
       "            campaign_title_type  \n",
       "campaign_id                      \n",
       "10u3c                  campaign  \n",
       "10v10                  campaign  \n",
       "10xis                  campaign  \n",
       "1ipyu0                 homepage  \n",
       "2ziaqw                 homepage  \n",
       "31qeuw                 homepage  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Review parsed results by diff campaign_title_type\n",
    "df.loc[:,['title','benefiter','organizer','campaign_title','campaign_title_type']].groupby('campaign_title_type').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse day,month & year from created_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing date:  99%|██████████████████████████████████████████████████████▋| 1765705/1777203 [01:30<00:00, 19833.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse Created by Heather Morrison on\n",
      "failed to parse Created by Fernando Hernandez on\n",
      "failed to parse Created 8. aprill 2017\n",
      "failed to parse Created by Skye Jensen on\n",
      "failed to parse Created by Ran Sin on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing date: 100%|███████████████████████████████████████████████████████| 1777203/1777203 [01:30<00:00, 19556.13it/s]\n"
     ]
    }
   ],
   "source": [
    "if use_tqdm: \n",
    "    tqdm.pandas(desc='Parsing date')\n",
    "    date_parsed_dicts = df.created_date.progress_apply(parse_created_date)\n",
    "else:\n",
    "    date_parsed_dicts = df.created_date.apply(parse_created_date)\n",
    "date_parsed_df = pd.DataFrame.from_records(date_parsed_dicts,index=date_parsed_dicts.index)                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some created_date have values \"Create X days ago\" and was parsed into the \"day\" field, fix this using archive_timestamp. these values are usually for campaign in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10u3c</th>\n",
       "      <td>2</td>\n",
       "      <td>November</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10v10</th>\n",
       "      <td>2</td>\n",
       "      <td>November</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10xis</th>\n",
       "      <td>2</td>\n",
       "      <td>November</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118qs</th>\n",
       "      <td>3</td>\n",
       "      <td>November</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12vck</th>\n",
       "      <td>8</td>\n",
       "      <td>November</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            day     month  year\n",
       "campaign_id                    \n",
       "10u3c         2  November  2010\n",
       "10v10         2  November  2010\n",
       "10xis         2  November  2010\n",
       "118qs         3  November  2010\n",
       "12vck         8  November  2010"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix the \"days ago rows\"\n",
    "days_ago_m = date_parsed_df.day.str.find('days ago') > -1\n",
    "days_ago_rows = date_parsed_df[days_ago_m]\n",
    "# Parse day month year from archived timestamp \n",
    "archived_ts= pd.DataFrame.from_records(df.loc[days_ago_rows.index, 'archive_timestamp'].apply(\n",
    "    lambda x: {\n",
    "        'day': x[6:8],\n",
    "        'month': x[4:6],\n",
    "        'year': x[0:4]\n",
    "    }),index=days_ago_rows.index)\n",
    "archived_ts['day'] = archived_ts['day'].astype(int)-days_ago_rows.day.apply(lambda x: int(x.replace('days ago','')))\n",
    "archived_ts['day']= archived_ts['day'].astype(str)\n",
    "# Update day month year fields \n",
    "date_parsed_df.update(archived_ts,overwrite=True)\n",
    "date_parsed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join parsed results into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both          1777203\n",
      "right_only          0\n",
      "left_only           0\n",
      "Name: _merge, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10u3c</th>\n",
       "      <td>Created November 2, 2010</td>\n",
       "      <td>2</td>\n",
       "      <td>November</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10v10</th>\n",
       "      <td>Created November 2, 2010</td>\n",
       "      <td>2</td>\n",
       "      <td>November</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10xis</th>\n",
       "      <td>Created by Leisa Talentino Dargis on November ...</td>\n",
       "      <td>2</td>\n",
       "      <td>November</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118qs</th>\n",
       "      <td>Created by Melanie Cristina Matyas on November...</td>\n",
       "      <td>3</td>\n",
       "      <td>November</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12vck</th>\n",
       "      <td>Created November 8, 2010</td>\n",
       "      <td>8</td>\n",
       "      <td>November</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  created_date day     month  \\\n",
       "campaign_id                                                                    \n",
       "10u3c                                 Created November 2, 2010   2  November   \n",
       "10v10                                 Created November 2, 2010   2  November   \n",
       "10xis        Created by Leisa Talentino Dargis on November ...   2  November   \n",
       "118qs        Created by Melanie Cristina Matyas on November...   3  November   \n",
       "12vck                                 Created November 8, 2010   8  November   \n",
       "\n",
       "             year  \n",
       "campaign_id        \n",
       "10u3c        2010  \n",
       "10v10        2010  \n",
       "10xis        2010  \n",
       "118qs        2010  \n",
       "12vck        2010  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_cols = ['day','month','year']\n",
    "df.drop(columns=parsed_cols,errors='ignore',inplace=True) #drop if exists\n",
    "df = df.merge(date_parsed_df[['day','month','year']],on='campaign_id',how='left',indicator=True)\n",
    "# See merge results\n",
    "print(df._merge.value_counts())\n",
    "df.drop(columns='_merge',inplace=True)\n",
    "df.loc[:,['created_date','day','month','year']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map non-English months to standard English months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_map_dict = {'février':'february','octobre':'october','juli':'july','junho':'june','09':'september','abril':'april',\n",
    "'março':'march','mars':'march','februar':'february','januar':'january', 'avril':'april','juin':'june',\n",
    "'juillet':'july','augustus':'august','mai':'may','mai':'may','märz':'march','juni':'June',\n",
    "'settembre':'september','gennaio':'january','septiembre':'september','mayo':'may',\n",
    "'décembre':'december','nisan':'April','maggio':'may','febbraio':'february',\n",
    "'marzo':'march','janvier':'january','dezember':'december','novembro':'november',\n",
    "'febrero':'february','aprile':'april','maio':'may','novembre':'november','mei':'may',\n",
    "'septembre':'september','oktober':'october','junio':'june','enero':'january','februari':'february','januari':'january',\n",
    "'fevereiro':'february','noviembre':'november','giugno':'june','agosto':'august'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map values\n",
    "mapped = df.month.str.lower().map(month_map_dict).str.capitalize()\n",
    "# if value was mapped keep the value, else keep original \n",
    "df.month=mapped.where(mapped.notna(),df.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure non-English month was mapped correctly to english month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['November', 'December', 'June', 'October', 'August', 'May', 'July',\n",
       "       'September', 'January', 'February', 'April', 'March', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.month.unique() # only english months should show up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for duplicates by campaign_title, organizer and parsed dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb=df.groupby(['campaign_title','organizer','day','month','year']).size().reset_index()\n",
    "po_dup_groups = gb[gb[0]>1]\n",
    "po_dups=df.merge(po_dup_groups,on=['campaign_title','organizer','day','month','year']).sort_values(['campaign_title','organizer','day','month','year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check why there's still duplicates even tho we already stratified by cleaned_title,created_date, and lowered-case location in Make_master_table.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>location</th>\n",
       "      <th>campaign_title</th>\n",
       "      <th>organizer</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>Created December 20, 2016</td>\n",
       "      <td>Organizer</td>\n",
       "      <td>!</td>\n",
       "      <td>Alli Sunshine</td>\n",
       "      <td>20</td>\n",
       "      <td>December</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>Created December 20, 2016</td>\n",
       "      <td>23144, US</td>\n",
       "      <td>!</td>\n",
       "      <td>Alli Sunshine</td>\n",
       "      <td>20</td>\n",
       "      <td>December</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>Created September 22, 2014</td>\n",
       "      <td>OJAI, CA</td>\n",
       "      <td>\"All Of Us\" Project</td>\n",
       "      <td>Cara Tower</td>\n",
       "      <td>22</td>\n",
       "      <td>September</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>Created September 22, 2014</td>\n",
       "      <td>Organizer</td>\n",
       "      <td>\"All Of Us\" Project</td>\n",
       "      <td>Cara Tower</td>\n",
       "      <td>22</td>\n",
       "      <td>September</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>Created December 27, 2014</td>\n",
       "      <td>GUTHRIE, OK</td>\n",
       "      <td>\"Chris &amp; Savanna need our help!\"</td>\n",
       "      <td>Jeri Cooper</td>\n",
       "      <td>27</td>\n",
       "      <td>December</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>Created December 27, 2014</td>\n",
       "      <td>NEWALLA, OK</td>\n",
       "      <td>\"Chris &amp; Savanna need our help!\"</td>\n",
       "      <td>Jeri Cooper</td>\n",
       "      <td>27</td>\n",
       "      <td>December</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Created November 9, 2013</td>\n",
       "      <td>Organizer</td>\n",
       "      <td>\"HELP ME HELP MY HOMETOWN\"</td>\n",
       "      <td>Kirby Lee Schious</td>\n",
       "      <td>9</td>\n",
       "      <td>November</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>Created November 9, 2013</td>\n",
       "      <td>OLYMPIA, WA</td>\n",
       "      <td>\"HELP ME HELP MY HOMETOWN\"</td>\n",
       "      <td>Kirby Lee Schious</td>\n",
       "      <td>9</td>\n",
       "      <td>November</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Created May 23, 2012</td>\n",
       "      <td>BLOOMINGTON, IN</td>\n",
       "      <td>\"Tom's Team\"- Winning this race together!</td>\n",
       "      <td>Kathleen Szczerbowicz Beaulieu</td>\n",
       "      <td>23</td>\n",
       "      <td>May</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Created May 23, 2012</td>\n",
       "      <td>Organizer</td>\n",
       "      <td>\"Tom's Team\"- Winning this race together!</td>\n",
       "      <td>Kathleen Szczerbowicz Beaulieu</td>\n",
       "      <td>23</td>\n",
       "      <td>May</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    created_date         location  \\\n",
       "1572   Created December 20, 2016        Organizer   \n",
       "1573   Created December 20, 2016        23144, US   \n",
       "1072  Created September 22, 2014         OJAI, CA   \n",
       "1073  Created September 22, 2014        Organizer   \n",
       "1110   Created December 27, 2014      GUTHRIE, OK   \n",
       "1111   Created December 27, 2014      NEWALLA, OK   \n",
       "696     Created November 9, 2013        Organizer   \n",
       "697     Created November 9, 2013      OLYMPIA, WA   \n",
       "334         Created May 23, 2012  BLOOMINGTON, IN   \n",
       "335         Created May 23, 2012        Organizer   \n",
       "\n",
       "                                 campaign_title  \\\n",
       "1572                                          !   \n",
       "1573                                          !   \n",
       "1072                        \"All Of Us\" Project   \n",
       "1073                        \"All Of Us\" Project   \n",
       "1110           \"Chris & Savanna need our help!\"   \n",
       "1111           \"Chris & Savanna need our help!\"   \n",
       "696                  \"HELP ME HELP MY HOMETOWN\"   \n",
       "697                  \"HELP ME HELP MY HOMETOWN\"   \n",
       "334   \"Tom's Team\"- Winning this race together!   \n",
       "335   \"Tom's Team\"- Winning this race together!   \n",
       "\n",
       "                           organizer day      month  year  \n",
       "1572                   Alli Sunshine  20   December  2016  \n",
       "1573                   Alli Sunshine  20   December  2016  \n",
       "1072                      Cara Tower  22  September  2014  \n",
       "1073                      Cara Tower  22  September  2014  \n",
       "1110                     Jeri Cooper  27   December  2014  \n",
       "1111                     Jeri Cooper  27   December  2014  \n",
       "696                Kirby Lee Schious   9   November  2013  \n",
       "697                Kirby Lee Schious   9   November  2013  \n",
       "334   Kathleen Szczerbowicz Beaulieu  23        May  2012  \n",
       "335   Kathleen Szczerbowicz Beaulieu  23        May  2012  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po_dups[['created_date','location','campaign_title','organizer','day','month','year']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates happened because of different original location or created_date, replace 'Organizer' values in location with 'none' and we'll keep the best duplicate in step 5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.location = df.location.replace('Organizer','none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find if any is in a non-English language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ers2244\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "show_cols =['gfm_url','cleaned_title','created_date','location','campaign_title','organizer','day','month','year']\n",
    "merge_cols  = ['campaign_title','organizer','day','month','year']\n",
    "non_eng_m = (~po_dups.status.apply(is_english)) | (~po_dups.goal.apply(is_english))\n",
    "po_dups_non_english=df.loc[:,show_cols].merge(po_dups.loc[non_eng_m,merge_cols],on=merge_cols).sort_values(by=merge_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gfm_url</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>created_date</th>\n",
       "      <th>location</th>\n",
       "      <th>campaign_title</th>\n",
       "      <th>organizer</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gfm_url, cleaned_title, created_date, location, campaign_title, organizer, day, month, year]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po_dups_non_english.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse goal into raised and goal amount "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: will fail for values where money was mentioned but not specified if it was raised or goal (e.g. '$8,130') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ryan/anaconda3/envs/cs109a/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "Parsing goal: 100%|██████████| 29477/29477 [00:01<00:00, 24775.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raised</th>\n",
       "      <th>goal</th>\n",
       "      <th>raised_amnt</th>\n",
       "      <th>raised_curr</th>\n",
       "      <th>goal_amnt</th>\n",
       "      <th>goal_curr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907051</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762225</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761195</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695470</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635848</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       raised goal  raised_amnt raised_curr  goal_amnt goal_curr\n",
       "907051    NaN  NaN          NaN         NaN        NaN       NaN\n",
       "762225    NaN  NaN          NaN         NaN        NaN       NaN\n",
       "761195    NaN  NaN          NaN         NaN        NaN       NaN\n",
       "695470    NaN  NaN          NaN         NaN        NaN       NaN\n",
       "635848    NaN  NaN          NaN         NaN        NaN       NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_tqdm:\n",
    "    tqdm.pandas(desc='Parsing goal')\n",
    "    goal_parsed_dicts = df.goal.progress_apply(get_raised_and_goal_amount,**dict(USD_only=False)) \n",
    "else:\n",
    "    goal_parsed_dicts = df.goal.apply(get_raised_and_goal_amount,**dict(USD_only=False)) \n",
    "# toogle USD_only to parse euro,pound or % also, else it'd return np.nan for these fields\n",
    "goal_parsed_df = pd.DataFrame.from_records(goal_parsed_dicts.to_list(),index=goal_parsed_dicts.index)\n",
    "goal_parsed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>goal</th>\n",
       "      <th>raised_amnt</th>\n",
       "      <th>goal_amnt</th>\n",
       "      <th>story</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907051</th>\n",
       "      <td>Created 3 days ago</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Those that knew Denzil Miller aka D will know ...</td>\n",
       "      <td>http://web.archive.org/web/20191205021724/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762225</th>\n",
       "      <td>Created 2 days ago</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>9 novembre 2019, triste tragédie pour deux je...</td>\n",
       "      <td>http://web.archive.org/web/20191112164148/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761195</th>\n",
       "      <td>Created 3 days ago</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>On December 9, Magnus is getting into a knife ...</td>\n",
       "      <td>http://web.archive.org/web/20191110055515/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695470</th>\n",
       "      <td>Created 7 days ago</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Holy Balls!! What an incredible success, thank...</td>\n",
       "      <td>http://web.archive.org/web/20191201233517/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635848</th>\n",
       "      <td>Created 2 days ago</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Betsaida “Betsy” Moreno was detained  by I.C.E...</td>\n",
       "      <td>http://web.archive.org/web/20190714121712/http...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              created_date  goal raised_amnt goal_amnt  \\\n",
       "907051  Created 3 days ago  none        none      none   \n",
       "762225  Created 2 days ago  none        none      none   \n",
       "761195  Created 3 days ago  none        none      none   \n",
       "695470  Created 7 days ago  none        none      none   \n",
       "635848  Created 2 days ago  none        none      none   \n",
       "\n",
       "                                                    story  \\\n",
       "907051  Those that knew Denzil Miller aka D will know ...   \n",
       "762225  9 novembre 2019, triste tragédie pour deux je...   \n",
       "761195  On December 9, Magnus is getting into a knife ...   \n",
       "695470  Holy Balls!! What an incredible success, thank...   \n",
       "635848  Betsaida “Betsy” Moreno was detained  by I.C.E...   \n",
       "\n",
       "                                                      url  \n",
       "907051  http://web.archive.org/web/20191205021724/http...  \n",
       "762225  http://web.archive.org/web/20191112164148/http...  \n",
       "761195  http://web.archive.org/web/20191110055515/http...  \n",
       "695470  http://web.archive.org/web/20191201233517/http...  \n",
       "635848  http://web.archive.org/web/20190714121712/http...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['created_date','goal','raised_amnt','goal_amnt','story','url']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse string inside 'raised' and 'goal' into amount and currency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see locations of campaigns that are not USD to see if they're based in the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_usd_m = (goal_parsed_df.raised_curr.str.find('$')==-1) | (goal_parsed_df.goal_curr.str.find('$')==-1)\n",
    "# look at location of these campaigns\n",
    "not_usd_locs=df.loc[not_usd_m,'location_city'].str.lower().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From manual checking, at least the first 180 locations are not but there are almost 20,000 locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "london, greater london, united kingdom            47\n",
       "dublin, ireland                                   34\n",
       "ireland                                           24\n",
       "madrid, m, spain                                  15\n",
       "none                                              14\n",
       "berlin, deutschland                               11\n",
       "houston, tx                                        9\n",
       "barcelona, ct, spain                               7\n",
       "paris, france                                      7\n",
       "chicago, il                                        6\n",
       "los angeles, ca                                    6\n",
       "portland, or                                       6\n",
       "phoenix, az                                        6\n",
       "brighton, south east england, united kingdom       5\n",
       "glasgow, scotland, united kingdom                  5\n",
       "manchester, north west england, united kingdom     5\n",
       "cork city, cork ireland                            4\n",
       "dallas, tx                                         4\n",
       "minneapolis, mn                                    4\n",
       "san jose, ca                                       4\n",
       "Name: location_city, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_usd_locs.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a code check using get_state_var() & state_is_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: location_city, dtype: int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_US_state_m = not_usd_locs.index.to_series().apply(get_state_var).apply(state_is_valid)\n",
    "# show any potential US location that have non_USD values\n",
    "not_usd_locs[valid_US_state_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check on values such as '2.2k','3M','1.5B' to make sure they're parsed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raised</th>\n",
       "      <th>goal</th>\n",
       "      <th>raised_amnt</th>\n",
       "      <th>raised_curr</th>\n",
       "      <th>goal_amnt</th>\n",
       "      <th>goal_curr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>540209</th>\n",
       "      <td>$3,999</td>\n",
       "      <td>$10k</td>\n",
       "      <td>3999.0</td>\n",
       "      <td>$</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539917</th>\n",
       "      <td>$6,248</td>\n",
       "      <td>$100k</td>\n",
       "      <td>6248.0</td>\n",
       "      <td>$</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540465</th>\n",
       "      <td>$8,120</td>\n",
       "      <td>$18k</td>\n",
       "      <td>8120.0</td>\n",
       "      <td>$</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539853</th>\n",
       "      <td>$4,402</td>\n",
       "      <td>$10.0M</td>\n",
       "      <td>4402.0</td>\n",
       "      <td>$</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495616</th>\n",
       "      <td>$2,078,890</td>\n",
       "      <td>$4.0M</td>\n",
       "      <td>2078890.0</td>\n",
       "      <td>$</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421802</th>\n",
       "      <td>$3,763</td>\n",
       "      <td>$123.5M</td>\n",
       "      <td>3763.0</td>\n",
       "      <td>$</td>\n",
       "      <td>123500000.0</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             raised      goal  raised_amnt raised_curr    goal_amnt goal_curr\n",
       "540209      $3,999       $10k       3999.0           $      10000.0         $\n",
       "539917      $6,248     $100k        6248.0           $     100000.0         $\n",
       "540465      $8,120       $18k       8120.0           $      18000.0         $\n",
       "539853      $4,402    $10.0M        4402.0           $   10000000.0         $\n",
       "495616  $2,078,890     $4.0M     2078890.0           $    4000000.0         $\n",
       "421802      $3,763    $123.5M       3763.0           $  123500000.0         $"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([goal_parsed_df.loc[goal_parsed_df.goal.str.find('k')>-1,:].head(3),\n",
    "goal_parsed_df.loc[goal_parsed_df.goal.str.lower().str.find('m')>-1,:].head(3),\n",
    "goal_parsed_df.loc[goal_parsed_df.goal.str.lower().str.find('b')>-1,:].head(3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join parsed results into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both          29477\n",
      "right_only        0\n",
      "left_only         0\n",
      "Name: _merge, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>raised_amnt</th>\n",
       "      <th>goal_amnt</th>\n",
       "      <th>currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907051</th>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762225</th>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761195</th>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695470</th>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635848</th>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        goal  raised_amnt  goal_amnt currency\n",
       "907051  none          NaN        NaN      NaN\n",
       "762225  none          NaN        NaN      NaN\n",
       "761195  none          NaN        NaN      NaN\n",
       "695470  none          NaN        NaN      NaN\n",
       "635848  none          NaN        NaN      NaN"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_goal_cols = ['raised_amnt','goal_amnt','currency']\n",
    "\n",
    "# change column name organizer -> poster and keeping everything else the same\n",
    "goal_parsed_df.columns = goal_parsed_df.columns.map(\n",
    "    goal_parsed_df.columns.to_series().replace({'goal_curr':'currency'}).to_dict())\n",
    "\n",
    "df.drop(columns=parsed_goal_cols,errors='ignore',inplace=True) # drop if exist\n",
    "df = df.merge(goal_parsed_df[parsed_goal_cols],right_index=True,left_index=True,how='left',indicator=True)\n",
    "# See merge results\n",
    "print(df._merge.value_counts())\n",
    "df.drop(columns='_merge',inplace=True)\n",
    "df.loc[:,['goal','raised_amnt','goal_amnt','currency']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure non-english goals got parsed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>raised_amnt</th>\n",
       "      <th>goal_amnt</th>\n",
       "      <th>currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [goal, raised_amnt, goal_amnt, currency]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_format_example = 'obiettivo'\n",
    "goal_f_m=df.goal.str.find(goal_format_example)>-1\n",
    "df.loc[goal_f_m,['goal','raised_amnt','goal_amnt','currency']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse status to get number of contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ryan/anaconda3/envs/cs109a/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "Standardizing status: 100%|██████████| 29477/29477 [00:00<00:00, 209247.04it/s]\n",
      "Parsing status: 100%|██████████| 29477/29477 [00:00<00:00, 43506.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndonor</th>\n",
       "      <th>num_contributors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907051</th>\n",
       "      <td>36</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762225</th>\n",
       "      <td>601</td>\n",
       "      <td>601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761195</th>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695470</th>\n",
       "      <td>55</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635848</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ndonor  num_contributors\n",
       "907051     36              36.0\n",
       "762225    601             601.0\n",
       "761195     24              24.0\n",
       "695470     55              55.0\n",
       "635848    NaN               NaN"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_tqdm:\n",
    "    tqdm.pandas(desc='Standardizing status')\n",
    "    s_status = df.num_donors.progress_apply(standardize_status)\n",
    "    tqdm.pandas(desc='Parsing status')\n",
    "    status_parsed_dicts = s_status.progress_apply(parse_status)\n",
    "else:\n",
    "    s_status = df.num_donors.apply(standardize_status)\n",
    "    status_parsed_dicts = s_status.apply(parse_status)\n",
    "status_parsed_df = pd.DataFrame.from_records(status_parsed_dicts.to_list(),index=status_parsed_dicts.index)\n",
    "status_parsed_df['num_contributors'] = pd.to_numeric(status_parsed_df.ndonor.apply(standardize_MBk_in_number_str))\n",
    "status_parsed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check on values such as '2.2k','3M','1.5B' to make sure they're parsed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndonor</th>\n",
       "      <th>num_contributors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ndonor, num_contributors]\n",
       "Index: []"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([status_parsed_df.loc[status_parsed_df.ndonor.str.find('k')>-1,:].head(3),\n",
    "status_parsed_df.loc[status_parsed_df.ndonor.str.lower().str.find('m')>-1,:].head(3),\n",
    "status_parsed_df.loc[status_parsed_df.ndonor.str.lower().str.find('b')>-1,:].head(3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join parsed results into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both          29477\n",
      "right_only        0\n",
      "left_only         0\n",
      "Name: _merge, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_donors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907051</th>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762225</th>\n",
       "      <td>601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761195</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695470</th>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635848</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_donors\n",
       "907051        36.0\n",
       "762225       601.0\n",
       "761195        24.0\n",
       "695470        55.0\n",
       "635848         NaN"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_status_cols = ['num_donors']\n",
    "\n",
    "# change column name organizer -> poster and keeping everything else the same\n",
    "status_parsed_df.columns = status_parsed_df.columns.map(\n",
    "    status_parsed_df.columns.to_series().replace({'num_contributors':'num_donors'}).to_dict())\n",
    "\n",
    "df.drop(columns=parsed_status_cols,errors='ignore',inplace=True) # drop if exist\n",
    "df = df.merge(status_parsed_df[parsed_status_cols],\n",
    "              right_index=True,left_index=True,how='left',indicator=True)\n",
    "\n",
    "# See merge results\n",
    "print(df._merge.value_counts())\n",
    "df.drop(columns='_merge',inplace=True)\n",
    "df.loc[:,['num_donors']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Clean variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coarse cleaning for location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state'] = df['location'].apply(get_state_var)\n",
    "df['old_loc_copy'] = df['location'].copy()\n",
    "df['location'] = df['location'].apply(remove_non_loc_info)\n",
    "df['other_loc'] = df['location'].apply(get_other_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean social media info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['likes'] = df['num_likes'].apply(get_social)\n",
    "df['shares'] = df['num_shares'].apply(get_social)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tag'] = df['tag'].str.lower()\n",
    "df['new_tag'] = df['tag'].apply(assign_new_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a. Drop duplicates based on parsed title and parsed date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep track of number of campaigns we will exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        original_campaign_count duplicate_url poor_wayback_qual  \\\n",
      "deleted                       0         20332             26541   \n",
      "total                   1856154       1835822           1809281   \n",
      "\n",
      "        duplicate_title_organizer_date_loc state_not_us not_USD not_cancer  \\\n",
      "deleted                              32078          NaN     NaN        NaN   \n",
      "total                              1777203          NaN     NaN        NaN   \n",
      "\n",
      "        tag_not_medical year_is_null failed_geocode last_null_county_check  \n",
      "deleted             NaN          NaN            NaN                    NaN  \n",
      "total               NaN          NaN            NaN                    NaN  \n"
     ]
    }
   ],
   "source": [
    "exclusion_df = pd.read_csv(data_io.input_cleaned/'gfm'/'exclusion_tracker_rd_1.csv',\n",
    "                          index_col = 0)\n",
    "\n",
    "\n",
    "#these numbers come from Make master table notebook\n",
    "exclusion_df.loc['total', 'original_campaign_count'] = 1856154\n",
    "exclusion_df.loc['deleted', 'original_campaign_count'] = 0\n",
    "\n",
    "exclusion_df.loc[0, 'original_campaign_num'] = 1856154\n",
    "exclusion_df.loc[1, 'original_campaign_num'] = 1856154\n",
    "\n",
    "exclusion_df.loc['total', 'duplicate_url'] = 1835822\n",
    "exclusion_df.loc['deleted', 'duplicate_url'] = (exclusion_df.loc['total', 'original_campaign_count'] - \n",
    "                                                exclusion_df.loc['total', 'duplicate_url'])\n",
    "\n",
    "exclusion_df.loc['total', 'poor_wayback_qual'] = 1809281\n",
    "exclusion_df.loc['deleted', 'poor_wayback_qual'] = (exclusion_df.loc['total', 'duplicate_url'] - \n",
    "                                                    exclusion_df.loc['total', 'poor_wayback_qual'])\n",
    "\n",
    "\n",
    "exclusion_df.loc['total', 'duplicate_title_organizer_date_loc'] = len(df)\n",
    "exclusion_df.loc['deleted', 'duplicate_title_organizer_date_loc'] = (exclusion_df.loc['total', 'poor_wayback_qual'] - \n",
    "                                                                    exclusion_df.loc['total', 'duplicate_title_organizer_date_loc'])\n",
    "\n",
    "exclusion_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to keep best duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_best_duplicate(df,subset=['title', 'location'],use_tqdm=False):\n",
    "    # For processing, these columns will be dropped later\n",
    "    df = df.assign(keep_this_duplicate=False,uid=range(df.shape[0]))\n",
    "    # Get potentially duplicated campaigns\n",
    "    mb_duplicates_m = df.duplicated(subset=subset, keep=False)\n",
    "    mb_duplicates = df.loc[mb_duplicates_m, :]\n",
    "    # Higher score means having this field != none is more important\n",
    "    importance_score = pd.Series({\n",
    "        'goal': 10,\n",
    "        'created_date': 10,\n",
    "        'status': 5,\n",
    "        'num_likes': 5,\n",
    "        'num_shares': 5,\n",
    "        'story': 3,\n",
    "        'location': 3\n",
    "    })\n",
    "\n",
    "    def get_index_of_best_duplicate(group):\n",
    "        group = group.copy().replace('none',np.nan)\n",
    "        # since we're edditing group, pandas will act all weird so need to copy\n",
    "        # Calculate parsing quality\n",
    "        \n",
    "        for idx, row in group.iterrows():\n",
    "            group.loc[idx, 'parsing_quality'] = (row[importance_score.index].notna() *\n",
    "                                                 importance_score).sum()\n",
    "        # Sort campaigns by timestamp and consequently quality\n",
    "        # More recent timestamp and higher quality will be the last row\n",
    "        # if any archive_timestamp is nan, just sort by quality\n",
    "        if group.archive_timestamp.isna().any():\n",
    "            return group.sort_values(by=['parsing_quality']).uid.iloc[-1]  # return uid of last row\n",
    "        else:\n",
    "            return group.sort_values(by=['archive_timestamp', 'parsing_quality'\n",
    "                                     ],na_position='first').uid.iloc[-1]  # return uid of last row\n",
    "    # Process each group of duplicate\n",
    "    if use_tqdm:\n",
    "        # use tqdm to make it pretty\n",
    "        tqdm.pandas(desc='Processing duplicates')\n",
    "        best_duplicate_uids = mb_duplicates.groupby(\n",
    "            subset).progress_apply(get_index_of_best_duplicate)\n",
    "    else:\n",
    "        best_duplicate_uids = mb_duplicates.groupby(\n",
    "            subset).apply(get_index_of_best_duplicate)\n",
    "\n",
    "    # Signal the duplicate to keep based on uid\n",
    "    df.loc[df.uid.isin(best_duplicate_uids), 'keep_this_duplicate'] = True\n",
    "    # Return rows that are not duplicates OR is the best duplicate\n",
    "    return df.loc[(df.keep_this_duplicate & mb_duplicates_m)\n",
    "                  | ~mb_duplicates_m, :].drop(\n",
    "                      columns=['keep_this_duplicate', 'uid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb=df.groupby(['campaign_title','organizer','day','month','year']).size().reset_index()\n",
    "po_dup_groups = gb[gb[0]>1]\n",
    "po_dups=df.merge(po_dup_groups,on=['campaign_title','organizer','day','month','year']).sort_values(['campaign_title','organizer','day','month','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "873\n"
     ]
    }
   ],
   "source": [
    "po_dups[['created_date','location','campaign_title','organizer','day','month','year']].head(20)\n",
    "temp = po_dups.drop_duplicates(subset=['campaign_title', 'organizer', 'day', 'month', 'year'])\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1777203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing duplicates: 100%|████████████████████████████████████████████████████████| 873/873 [00:06<00:00, 125.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1776317\n"
     ]
    }
   ],
   "source": [
    "old_df = df.copy()\n",
    "print(len(old_df))\n",
    "df = keep_best_duplicate(old_df, subset=['campaign_title','organizer', 'day','month', 'year'], use_tqdm=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure all duplicates were resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb=df.groupby(['campaign_title','organizer','day','month','year']).size().reset_index()\n",
    "po_dup_groups = gb[gb[0]>1]\n",
    "po_dups=df.merge(po_dup_groups,on=['campaign_title','organizer','day','month','year']).sort_values(['campaign_title','organizer','day','month','year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>location</th>\n",
       "      <th>campaign_title</th>\n",
       "      <th>organizer</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [created_date, location, campaign_title, organizer, day, month, year]\n",
       "Index: []"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po_dups[['created_date','location','campaign_title','organizer','day','month','year']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        original_campaign_count duplicate_url poor_wayback_qual  \\\n",
      "deleted                       0         20332             26541   \n",
      "total                   1856154       1835822           1809281   \n",
      "\n",
      "        duplicate_title_organizer_date_loc state_not_us not_USD not_cancer  \\\n",
      "deleted                              32078          NaN     NaN        NaN   \n",
      "total                              1777203          NaN     NaN        NaN   \n",
      "\n",
      "        tag_not_medical year_is_null failed_geocode last_null_county_check  \\\n",
      "deleted             NaN          NaN            NaN                    NaN   \n",
      "total               NaN          NaN            NaN                    NaN   \n",
      "\n",
      "         duplicate_title_organizer_date  \n",
      "deleted                           886.0  \n",
      "total                         1776317.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "exclusion_df.loc['total', 'duplicate_title_organizer_date'] = len(df)\n",
    "exclusion_df.loc['deleted', 'duplicate_title_organizer_date'] = (exclusion_df.loc['total', 'duplicate_title_organizer_date_loc'] -\n",
    "                                                                    exclusion_df.loc['total', 'duplicate_title_organizer_date'])\n",
    "print(exclusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "save=False\n",
    "if save:\n",
    "    df.to_csv(data_io.input_cleaned/'gfm'/'all_campaigns.csv',sep='|',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Exclude cases and update exclusion df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up columns for exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cancer'] = df.apply(lambda x: find_cancer_story_title(x['story'], x['title']),axis=1)\n",
    "df['cancer_in_story'] = df['story'].apply(cancer_in_x)\n",
    "df['cancer_in_title'] = df['title'].apply(cancer_in_x)\n",
    "#df['immunotherapy'] = df['story'].apply(immunotherapy_mention)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    1520344\n",
      "True      255973\n",
      "Name: cancer, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['cancer'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state_in_us'] = df['state'].apply(state_is_valid)\n",
    "                                      \n",
    "df['status_is_english'] = df['status'].apply(is_english)\n",
    "df['money_is_english'] = df['goal'].apply(is_english)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_campaign_count</th>\n",
       "      <th>duplicate_url</th>\n",
       "      <th>poor_wayback_qual</th>\n",
       "      <th>duplicate_title_organizer_date_loc</th>\n",
       "      <th>state_not_us</th>\n",
       "      <th>not_USD</th>\n",
       "      <th>not_cancer</th>\n",
       "      <th>tag_not_medical</th>\n",
       "      <th>year_is_null</th>\n",
       "      <th>failed_geocode</th>\n",
       "      <th>last_null_county_check</th>\n",
       "      <th>duplicate_title_organizer_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deleted</th>\n",
       "      <td>0</td>\n",
       "      <td>20332</td>\n",
       "      <td>26541</td>\n",
       "      <td>32078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>886.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>1856154</td>\n",
       "      <td>1835822</td>\n",
       "      <td>1809281</td>\n",
       "      <td>1777203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1776317.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        original_campaign_count duplicate_url poor_wayback_qual  \\\n",
       "deleted                       0         20332             26541   \n",
       "total                   1856154       1835822           1809281   \n",
       "\n",
       "        duplicate_title_organizer_date_loc state_not_us not_USD not_cancer  \\\n",
       "deleted                              32078          NaN     NaN        NaN   \n",
       "total                              1777203          NaN     NaN        NaN   \n",
       "\n",
       "        tag_not_medical year_is_null failed_geocode last_null_county_check  \\\n",
       "deleted             NaN          NaN            NaN                    NaN   \n",
       "total               NaN          NaN            NaN                    NaN   \n",
       "\n",
       "         duplicate_title_organizer_date  \n",
       "deleted                           886.0  \n",
       "total                         1776317.0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1528918\n",
      "        original_campaign_count duplicate_url poor_wayback_qual  \\\n",
      "deleted                       0         20332             26541   \n",
      "total                   1856154       1835822           1809281   \n",
      "\n",
      "        duplicate_title_organizer_date_loc state_not_us not_USD not_cancer  \\\n",
      "deleted                              32078       247399     NaN        NaN   \n",
      "total                              1777203      1528918     NaN        NaN   \n",
      "\n",
      "        tag_not_medical year_is_null failed_geocode last_null_county_check  \\\n",
      "deleted             NaN          NaN            NaN                    NaN   \n",
      "total               NaN          NaN            NaN                    NaN   \n",
      "\n",
      "         duplicate_title_organizer_date  \n",
      "deleted                           886.0  \n",
      "total                         1776317.0  \n"
     ]
    }
   ],
   "source": [
    "##EXCLUDE BASED ON STATE\n",
    "df = df[df['state_in_us'] == True]\n",
    "print(len(df))\n",
    "exclusion_df.loc['deleted', 'state_not_us'] = (exclusion_df.loc['total', 'duplicate_title_organizer_date'] - \n",
    "                                              len(df))\n",
    "exclusion_df.loc['total', 'state_not_us'] = len(df)\n",
    "\n",
    "exclusion_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247399"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1776317 - 1528918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1526336\n",
      "2582\n",
      "        original_campaign_count duplicate_url poor_wayback_qual  \\\n",
      "deleted                       0         20332             26541   \n",
      "total                   1856154       1835822           1809281   \n",
      "\n",
      "        duplicate_title_organizer_date_loc state_not_us  not_USD not_cancer  \\\n",
      "deleted                              32078       247399     2582        NaN   \n",
      "total                              1777203      1528918  1526336        NaN   \n",
      "\n",
      "        tag_not_medical year_is_null failed_geocode last_null_county_check  \\\n",
      "deleted             NaN          NaN            NaN                    NaN   \n",
      "total               NaN          NaN            NaN                    NaN   \n",
      "\n",
      "         duplicate_title_organizer_date  \n",
      "deleted                           886.0  \n",
      "total                         1776317.0  \n"
     ]
    }
   ],
   "source": [
    "# Exclude campaigns with goal not in USD since none would be from US (see test in step 4a)\n",
    "last_col = 'state_not_us'\n",
    "df = df.loc[df.goal.str.find('$')>-1,:]\n",
    "exclusion_df.loc['deleted', 'not_USD'] = exclusion_df.loc['total', last_col] - len(df)\n",
    "exclusion_df.loc['total', 'not_USD'] = len(df)\n",
    "\n",
    "print(len(df))\n",
    "print(exclusion_df.loc['total', last_col] - len(df))\n",
    "print(exclusion_df)\n",
    "last_col = 'not_USD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a copy as all US campaigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        original_campaign_count duplicate_url poor_wayback_qual  \\\n",
      "deleted                       0         20332             26541   \n",
      "total                   1856154       1835822           1809281   \n",
      "\n",
      "        duplicate_title_organizer_date_loc state_not_us  not_USD  not_cancer  \\\n",
      "deleted                              32078       247399     2582     1304279   \n",
      "total                              1777203      1528918  1526336      222057   \n",
      "\n",
      "        tag_not_medical year_is_null failed_geocode last_null_county_check  \\\n",
      "deleted             NaN          NaN            NaN                    NaN   \n",
      "total               NaN          NaN            NaN                    NaN   \n",
      "\n",
      "         duplicate_title_organizer_date  \n",
      "deleted                           886.0  \n",
      "total                         1776317.0  \n",
      "222057\n",
      "1304279\n"
     ]
    }
   ],
   "source": [
    "df = df[df['cancer']==True]\n",
    "exclusion_df.loc['deleted', 'not_cancer'] = exclusion_df.loc['total', last_col] - len(df)\n",
    "exclusion_df.loc['total', 'not_cancer'] = len(df)\n",
    "print(exclusion_df)\n",
    "print(len(df))\n",
    "print(exclusion_df.loc['total', last_col] - len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        original_campaign_count duplicate_url poor_wayback_qual  \\\n",
      "deleted                       0         20332             26541   \n",
      "total                   1856154       1835822           1809281   \n",
      "\n",
      "        duplicate_title_organizer_date_loc state_not_us  not_USD  not_cancer  \\\n",
      "deleted                              32078       247399     2582     1304279   \n",
      "total                              1777203      1528918  1526336      222057   \n",
      "\n",
      "         tag_not_medical year_is_null failed_geocode last_null_county_check  \\\n",
      "deleted            77154          NaN            NaN                    NaN   \n",
      "total             144903          NaN            NaN                    NaN   \n",
      "\n",
      "         duplicate_title_organizer_date  \n",
      "deleted                           886.0  \n",
      "total                         1776317.0  \n",
      "144903\n",
      "77154\n"
     ]
    }
   ],
   "source": [
    "last_col = 'not_cancer'\n",
    "#Exclude on tag\n",
    "df = df[pd.isnull(df['new_tag'])==False]\n",
    "exclusion_df.loc['deleted', 'tag_not_medical'] = exclusion_df.loc['total', last_col] - len(df)\n",
    "exclusion_df.loc['total', 'tag_not_medical'] = len(df)\n",
    "print(exclusion_df)\n",
    "print(len(df))\n",
    "print(exclusion_df.loc['total', last_col] - len(df))\n",
    "last_col = 'tag_not_medical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "print(df.year.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        original_campaign_count duplicate_url poor_wayback_qual  \\\n",
      "deleted                       0         20332             26541   \n",
      "total                   1856154       1835822           1809281   \n",
      "\n",
      "        duplicate_title_organizer_date_loc state_not_us  not_USD  not_cancer  \\\n",
      "deleted                              32078       247399     2582     1304279   \n",
      "total                              1777203      1528918  1526336      222057   \n",
      "\n",
      "         tag_not_medical  year_is_null failed_geocode last_null_county_check  \\\n",
      "deleted            77154           151            NaN                    NaN   \n",
      "total             144903        144752            NaN                    NaN   \n",
      "\n",
      "         duplicate_title_organizer_date  \n",
      "deleted                           886.0  \n",
      "total                         1776317.0  \n",
      "144752\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "#Exclude on year if null\n",
    "\n",
    "df = df.dropna(subset=['year'])\n",
    "exclusion_df.loc['deleted', 'year_is_null'] = exclusion_df.loc['total', last_col] - len(df)\n",
    "exclusion_df.loc['total', 'year_is_null'] = len(df)\n",
    "print(exclusion_df)\n",
    "print(len(df))\n",
    "print(exclusion_df.loc['total', last_col] - len(df))\n",
    "exclusion_df.to_csv(data_io.input_cleaned/'gfm'/'exclusion_tracker_rd_2.csv')\n",
    "last_col = 'year_is_null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(data_io.input_cleaned/'gfm'/'cancer_campaigns_no_locs.xlsx',\n",
    "                        engine='xlsxwriter',\n",
    "                        options=EXCEL_OPTIONS)\n",
    "df.to_excel(writer, encoding='utf-8-sig')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Generate unique location spreadsheet and merge with existing (if exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_canada(x):\n",
    "    #'ANA NAN'\n",
    "    if type(x) != str:\n",
    "        return False\n",
    "    if x[-2:] == 'ca':\n",
    "        if x[0].isalpha():\n",
    "            if x[1].isdigit():\n",
    "                if x[2].isalpha():\n",
    "                    if x[3].isdigit:\n",
    "                        if x[4].isalpha:\n",
    "                            if x[5].isdigit:\n",
    "                                return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True    24975\n",
      "Name: state_in_us, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#NOTE: if none of the locations have been geocoded, you need to save this file and run it through the geocoder\n",
    "new_unique_locs = df.drop_duplicates(subset=['location'], keep='first')\n",
    "print(new_unique_locs['state_in_us'].value_counts())\n",
    "new_unique_locs = new_unique_locs[['location','state', 'other_loc']]\n",
    "new_unique_locs['possible_canada'] = new_unique_locs['location'].apply(check_if_canada)\n",
    "len(new_unique_locs)\n",
    "save = True\n",
    "if save:\n",
    "    writer = pd.ExcelWriter(data_io.input_cleaned/'geolocations'/'unique_locations_to_scrape_all_years.xlsx',\n",
    "                            engine='xlsxwriter',\n",
    "                            options={'strings_to_urls': False,\n",
    "                                     'strings_to_formulas': False})\n",
    "    new_unique_locs.to_excel(writer, encoding='utf-8-sig', index = False)\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs109a",
   "language": "python",
   "name": "cs109a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
