{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": null,
>>>>>>> 5e206344ad9081178693706170e97a0a881a60e3
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import data_io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": null,
>>>>>>> 5e206344ad9081178693706170e97a0a881a60e3
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_locations = pd.read_excel(data_io.input_cleaned/'geolocations'/'cancer_unique_locs_w_fips_mapbox.xlsx',\n",
    "                                    encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25084"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 5e206344ad9081178693706170e97a0a881a60e3
   "source": [
    "len(unique_locations)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": null,
>>>>>>> 5e206344ad9081178693706170e97a0a881a60e3
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(data_io.input_cleaned/'cancer_campaigns_no_locs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": null,
>>>>>>> 5e206344ad9081178693706170e97a0a881a60e3
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_df = pd.read_csv(data_io.input_cleaned/'gfm'/'exclusion_tracker_rd_2.csv',\n",
    "                              index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 5e206344ad9081178693706170e97a0a881a60e3
   "source": [
    "#drop locations that didn't geocode\n",
    "unique_locations.loc[unique_locations['county']=='none', 'county'] = np.nan\n",
    "unique_locations.loc[unique_locations['county_fips']=='nan', 'county_fips'] = np.nan\n",
    "\n",
    "unique_locations.dropna(subset=['county'], inplace=True)\n",
    "locations = unique_locations['location'].to_list()\n",
    "\n",
    "county_dict = dict(zip(locations, unique_locations['county'].to_list()))\n",
    "fips_dict = dict(zip(locations, unique_locations['county_fips'].to_list()))\n",
    "\n",
    "\n",
    "df['county'] = df['location'].map(county_dict)\n",
    "df['county_fips'] = df['location'].map(fips_dict)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 5e206344ad9081178693706170e97a0a881a60e3
   "source": [
    "df['county'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_df.loc['deleted', 'failed_geocode'] = df['county'].isnull().sum()\n",
    "df = df.dropna(subset = ['county'])\n",
    "exclusion_df.loc['total', 'failed_geocode'] = len(df)\n",
    "exclusion_df.to_csv(data_io.input_cleaned/'gfm'/'final_exclusion_tracker.csv')\n",
    "geo_fail = df[pd.isnull(df['county'])]\n",
    "#save failed geocodes to make sure nothing in the US failed\n",
    "save = False\n",
    "if save:\n",
    "    geo_fail.to_csv(data_io.input_cleaned/'gfm'/'master_failed_geocode.csv', encoding='utf-8-sig')\n",
    "df.dropna(subset=['county'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define text mining functions"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": null,
>>>>>>> 5e206344ad9081178693706170e97a0a881a60e3
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for additional text mining\n",
    "SEARCH_OPTIONS = pd.read_csv(data_io.input_cleaned/'gfm'/'free_text_search_terms.csv')\n",
    "\n",
    "SEARCH_DICT = {'cancer_type': SEARCH_OPTIONS['cancer_type'].dropna().to_list(),\n",
    "              'insurance_type': SEARCH_OPTIONS['insurance_type'].dropna().to_list(),\n",
    "              'oop_type': SEARCH_OPTIONS['oop_type'].dropna().to_list(),\n",
    "              'tx_type':SEARCH_OPTIONS['tx_type'].dropna().to_list(),\n",
    "              'clin_trial':SEARCH_OPTIONS['clin_trial'].dropna().to_list(),\n",
    "              'complementary':SEARCH_OPTIONS['complementary'].dropna().to_list(),\n",
    "              'battle':SEARCH_OPTIONS['battle'].dropna().to_list(),\n",
    "              'self_reliance':SEARCH_OPTIONS['self_reliance'].dropna().to_list(),\n",
    "              'journey': SEARCH_OPTIONS['journey'].dropna().to_list(),\n",
    "              'thank': SEARCH_OPTIONS['thank'].dropna().to_list(),\n",
    "              'nice':SEARCH_OPTIONS['nice'].dropna().to_list(),\n",
    "              'brave':SEARCH_OPTIONS['brave'].dropna().to_list(),\n",
    "              'financial_distress': SEARCH_OPTIONS['financial_distress'].dropna().to_list()}\n",
    "\n",
    "    \n",
    "def create_dict(search_type):\n",
    "    key_col = 'collapsed_'+search_type\n",
    "    new = SEARCH_OPTIONS.dropna(subset=[search_type])\n",
    "    this_dict = pd.Series(new[key_col].values,index=new[search_type].values).to_dict()\n",
    "    \n",
    "    return this_dict\n",
    "\n",
    "INSURE_DICT = create_dict('insurance_type')\n",
    "#OOP_DICT = create_dict('oop_type')\n",
    "import string   \n",
    "import regex as re\n",
    "def extract_search_term_regex(x, search_type = 'cancer_type', return_context = False,\n",
    "                             find_uninsured = False, collapse_dict = 'none'):\n",
    "    if type(x) == str:\n",
    "        x = x.lower()\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    search_terms = SEARCH_DICT[search_type]\n",
    "    #match only if char after match is a space or punctuation\n",
    "    if 'cancer' in search_type:\n",
    "        for s in search_terms:\n",
    "            smatch = re.search(s+'\\W', x)\n",
    "            if smatch:\n",
    "                if return_context == True:\n",
    "                    end_smatch = smatch.span()[1]\n",
    "                    new = x[smatch.span()[0]:]\n",
    "                    new = new[0: new.find('.')]\n",
    "                    return new\n",
    "\n",
    "                return(x[smatch.span()[0]:smatch.span()[1]])\n",
    "        return np.nan\n",
    "    else:\n",
    "        return_val = False\n",
    "        uninsure = False\n",
    "        mention = []\n",
    "        collapsed_mention = []\n",
    "        for s in search_terms:\n",
    "            smatch = re.search(s, x)\n",
    "            \n",
    "            if smatch:\n",
    "                if return_context == True:\n",
    "                    \n",
    "                    new = x[smatch.span()[0]:smatch.span()[1]]\n",
    "                    #print(new)\n",
    "                    mention.append(new)\n",
    "                \n",
    "                if find_uninsured == True:\n",
    "                    if INSURE_DICT[s] == 'uninsured' or INSURE_DICT[s] == 'underunisured':\n",
    "                        return True\n",
    "                else:\n",
    "                    return_val = True\n",
    "                \n",
    "                if type(collapse_dict) != str:\n",
    "                    collapsed_mention.append(collapse_dict[s])\n",
    "\n",
    "                return_val = True\n",
    "                \n",
    "        if len(mention) >= 1:\n",
    "            mention = ','.join(mention)\n",
    "        else:\n",
    "            mention = None\n",
    "            \n",
    "        if len(collapsed_mention) >= 1:\n",
    "            collapsed_mention = np.unique(np.asarray(collapsed_mention))\n",
    "            collapsed_mention = list(collapsed_mention)\n",
    "            collapsed_mention = ','.join\n",
    "        else:\n",
    "            collapsed_mention = None\n",
    "            \n",
    "        if type(collapse_dict)!= str:\n",
    "            return collapsed_mention\n",
    "        \n",
    "        return mention if return_context == True else return_val\n",
    "\n",
    "def search_story_and_title(story, title, search_type):\n",
    "    story_truth = extract_search_term_regex(story, search_type = search_type)\n",
    "    title_truth = extract_search_term_regex(title, search_type = search_type)\n",
    "    if title_truth == True or story_truth == True:\n",
    "        return True\n",
    "    elif title_truth == False and story_truth == False:\n",
    "        return False\n",
    "\n",
    "def get_all_mentions(story, title, search_type):\n",
    "    story_truth = extract_search_term_regex(story, \n",
    "                                            search_type = search_type, \n",
    "                                            return_context = True)\n",
    "    title_truth = extract_search_term_regex(title, \n",
    "                                            search_type = search_type, \n",
    "                                            return_context = True)\n",
    "    if type(story_truth) == str:\n",
    "        if type(title_truth) == str:\n",
    "            story_truth += title_truth\n",
    "        return story_truth\n",
    "    elif type(title_truth) == str:\n",
    "        return title_truth\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#Returns a comma separated string of the features that match the search in question\n",
    "def extract_feature(story, feature = 'tx_type_search', title = None):\n",
    "    features = SEARCH_DICT[feature]\n",
    "    if pd.isnull(title):\n",
    "        searches = [story]\n",
    "    else:\n",
    "        searches = [story, title]\n",
    "        \n",
    "    return_str = ''\n",
    "    for x in searches:\n",
    "        if type(x) == str:\n",
    "            x = x.lower()\n",
    "            for f in features:\n",
    "                if f in x:\n",
    "                    if len(return_str) == 0:\n",
    "                        return_str += f\n",
    "                    else:\n",
    "                        return_str += ', '\n",
    "                        return_str += f\n",
    "                        \n",
    "    if len(return_str) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return return_str\n",
    "\n",
    "\n",
    "def collapse_feature(mentions, feature_dict):\n",
    "    if type(mentions) == str:\n",
    "        temp_mentions = mentions.split(', ')\n",
    "        new_mentions = []\n",
    "        for t in temp_mentions:\n",
    "            new_mentions.append(feature_dict[t])\n",
    "        \n",
    "        new_mentions = np.unique(new_mentions)\n",
    "        \n",
    "        new_mentions = ', '.join(new_mentions)\n",
    "        return new_mentions\n",
    "\n",
    "\n",
    "    \n",
    "def assign_num_occurrences(mentions):\n",
    "    if type(mentions) == str:\n",
    "        if ',' in mentions:\n",
    "            new = mentions.split(',')\n",
    "            return len(new)\n",
    "        else:\n",
    "            if mentions != '':\n",
    "                return 1\n",
    "        \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": null,
>>>>>>> 5e206344ad9081178693706170e97a0a881a60e3
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Mine each text feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching for oop_type\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> 5e206344ad9081178693706170e97a0a881a60e3
   "source": [
    "recode = True\n",
    "if recode:\n",
    "    #Look for clinical/financial details\n",
    "    recode_feats_to_search = ['oop_type', 'insurance_type', 'tx_type',\n",
    "                                 'cancer_type']\n",
    "    df['story_and_title'] = df['title'] + ' ' + df['story']\n",
    "    for r in recode_feats_to_search:\n",
    "        new_col = r + '_is_mentioned'\n",
    "        print(f\"searching for {r}\")\n",
    "        df[new_col] = df.apply(lambda x: extract_search_term_regex(x['story_and_title'],\n",
    "                                                            search_type = r),\n",
    "                                       axis = 1)\n",
    "        print(f\"extracting {r}\")\n",
    "        df[r] = df.apply(lambda x: extract_search_term_regex(x['story_and_title'],\n",
    "                                                            search_type = r,\n",
    "                                                            return_context = True),\n",
    "                                       axis = 1)\n",
    "        recode = 'collapsed_' + r\n",
    "        \n",
    "        feat_dict = create_dict(r)\n",
    "        print(f\"collapsing {r}\")\n",
    "        df[recode] = df.apply(lambda x: extract_search_term_regex(x['story_and_title'],\n",
    "                                                            search_type = r,\n",
    "                                                            collapse_dict = feat_dict),\n",
    "                                       axis = 1)\n",
    "\n",
    "    \n",
    "    df['num_tx'] = df['collapsed_tx_type'].apply(assign_num_occurrences)\n",
    "    df['num_oop'] = df['collapsed_oop_type'].apply(assign_num_occurrences)\n",
    "    df['uninsured'] = df.apply(lambda x: extract_search_term_regex(x['story_and_title'],\n",
    "                                                                search_type = 'insurance_type',\n",
    "                                                                find_uninsured = True),\n",
    "                                       axis = 1)\n",
    "    #Look for worth indicators\n",
    "    worth_indicators = ['brave', 'nice', 'thank', 'self_reliance', 'battle']\n",
    "    \n",
    "    for w in worth_indicators:\n",
    "        new_col = w + '_is_mentioned'\n",
    "        print(f\"searching for {w}\")\n",
    "        df[new_col] = df.apply(lambda x: extract_search_term_regex(x['story_and_title'],\n",
    "                                                            search_type = w),\n",
    "                                       axis = 1)\n",
    "        print(f\"extracting {w}\")\n",
    "        df[w] = df.apply(lambda x: extract_search_term_regex(x['story_and_title'],\n",
    "                                                            search_type = w,\n",
    "                                                            return_context = True),\n",
    "                                       axis = 1)\n",
    "    save = True\n",
    "    if save:\n",
    "        writer = pd.ExcelWriter(data_io.input_cleaned/'gfm'/'cancer_w_locs_and_text_features.xlsx',\n",
    "                               engine='xlsxwriter', options = EXCEL_OPTIONS)\n",
    "        df.to_excel(writer, encoding='utf-8', index= False)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.7.6"
=======
   "version": "3.6.8"
>>>>>>> 5e206344ad9081178693706170e97a0a881a60e3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
