{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import winsorize\n",
    "import pandas as pd\n",
    "import data_io\n",
    "import utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(data_io.input_cleaned))\n",
    "EXCEL_OPTIONS = {'strings_to_urls': False,\n",
    "                 'strings_to_formulas': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists(data_io.input_cleaned/'gfm'/'cancer_w_locs_and_text_features_census.xlsx'):\n",
    "    merge_ndi = False\n",
    "    print('path exists')\n",
    "    df = pd.read_excel(data_io.input_cleaned/'gfm'/'cancer_w_locs_and_text_features_census.xlsx', \n",
    "                       encoding = 'utf-8')\n",
    "else:\n",
    "    print('still need to merge GFM and Census data')\n",
    "    df = pd.read_excel(data_io.input_cleaned/'gfm'/'cancer_w_locs_and_text_features.xlsx', \n",
    "                       encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format variables for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'winsorized_goal' not in df.columns.values:\n",
    "    #citation to support winsorizing https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5548942/#!po=41.6667\n",
    "    df['winsorized_goal'] = winsorize(df['goal_amnt'], limits = .05)\n",
    "    df.loc[pd.isnull(df['goal_amnt']), 'winsorized_goal'] = np.nan\n",
    "    print(df['winsorized_goal'].mean())\n",
    "    print(df['goal_amnt'].mean())\n",
    "    df['changed_goal'] = df['winsorized_goal'] != df['goal_amnt']\n",
    "    df.loc[pd.isnull(df['winsorized_goal']), 'changed_goal'] = False\n",
    "    print('Number of campaigns that were changed in winsorization: ', df.changed_goal.value_counts())\n",
    "    df['orig_percent_goal'] = df['raised_amnt']/df['goal_amnt']\n",
    "else:\n",
    "    print('winsorization already done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'percent_goal' not in df.columns.values:\n",
    "    df['percent_goal'] = df['raised_amnt']/df['winsorized_goal']\n",
    "    print('Number of campaigns with goal amount > 100%: ', len(df[df['percent_goal']>1.]))\n",
    "    df.loc[df['orig_percent_goal']>1., 'orig_percent_goal'] = 1.\n",
    "    df.loc[df['percent_goal']>1., 'percent_goal'] = 1.\n",
    "    df['orig_met_goal'] = df['orig_percent_goal'] >=1.\n",
    "    df['met_goal'] = df['percent_goal'] >=1.\n",
    "    print('Number of campaigns meeting goal pre-transform: ', df['orig_met_goal'].value_counts())\n",
    "    print('Number of campaigns meeting goal post-transform: ',df['met_goal'].value_counts())\n",
    "else:\n",
    "    print('percent goal already calculated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['log_raised_amnt'] = np.log(df['raised_amnt'])\n",
    "df.loc[np.isinf(df['log_raised_amnt']), 'log_raised_amnt'] = np.nan\n",
    "\n",
    "df['avg_contribution'] = df['raised_amnt']/df['num_contributors']\n",
    "df.loc[np.isinf(df['avg_contribution']), 'avg_contribution'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert location info to strings\n",
    "df['state_fips'] = df['state_x'].map(utils.state_fips)\n",
    "df['county_fips'] = df['county_fips_int'].apply(utils.format_county_fip)\n",
    "\n",
    "df['state_county_fips_str'] = df['state_fips'] + df['county_fips']\n",
    "df['state_county_fips_str'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. After running get_census_data.ipynb and clustr.R, calculate the Neighborhood Deprivation Index and merge with the GFM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after running the PCA in R on the census variables, load the dataset back in to compute the deprivation index\n",
    "def get_ndi_quartiles():\n",
    "    pca = pd.read_csv(data_io.input_cleaned/'census'/'census_w_factor_weights.csv')\n",
    "    census = pd.read_csv(data_io.input_cleaned/'census'/'acs_five_year_est.csv')\n",
    "    census['state_county_fips_str'] = census['state_county_fips_str'].apply(utils.format_state_county_fip)\n",
    "    pca['state_county_fips_str'] = pca['state_county_fips'].apply(utils.format_state_county_fip)\n",
    "\n",
    "    colnames = pca.columns.to_list()\n",
    "    cols_to_sum = [i for i in colnames if 'weighted' in i]\n",
    "\n",
    "    #pca = pca[temp_cols]\n",
    "    print(colnames)\n",
    "    pca['sum'] = 0\n",
    "    for c in cols_to_sum:\n",
    "        pca['sum'] += pca[c]\n",
    "\n",
    "    cols_to_sum.append('state_county_fips_str')\n",
    "    cols_to_sum.append('sum')\n",
    "    pca = pca[cols_to_sum]\n",
    "    from sklearn import preprocessing\n",
    "    pca['standardized_ndi'] = preprocessing.scale(pca['sum'])\n",
    "    pca = pd.merge(pca, census, how='left', on='state_county_fips_str')\n",
    "    \n",
    "    QUANTS = (np.quantile(pca['standardized_ndi'].values, [.25, .5, .75]))\n",
    "\n",
    "    def _get_quantile(x):\n",
    "        if x <= QUANTS[0]:\n",
    "            return 1\n",
    "        if x > QUANTS[0] and x <= QUANTS[1]:\n",
    "            return 2\n",
    "        if x > QUANTS[1] and x <= QUANTS[2]:\n",
    "            return 3\n",
    "        if x > QUANTS[2]:\n",
    "            return 4\n",
    "    cols_to_drop = [c for c in pca.columns.to_list() if 'weighted' in c]\n",
    "    print(cols_to_drop)\n",
    "    pca['ndi_quantile'] = pca['standardized_ndi'].apply(_get_quantile)\n",
    "    \n",
    "    pca.drop(columns = cols_to_drop, inplace=True)\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Census stats by NDI quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptives for PCA/census vars\n",
    "if merge_ndi:\n",
    "    ndi_df = get_ndi_quartiles()\n",
    "    ndi_map = {1: 'NDI Quartile 1 (least deprived)',\n",
    "                2: 'NDI Quartile 2',\n",
    "                3: 'NDI Quartile 3',\n",
    "                4: 'NDI Quartile 4 (most deprived)'\n",
    "              }\n",
    "\n",
    "    census_vars = pd.read_csv(data_io.input_cleaned/'census'/'census_variables.csv')\n",
    "    census_var_dict = dict(zip(census_vars['variable_label'].to_list(), census_vars['pretty_label'].to_list()))\n",
    "\n",
    "    census_var_dict['percent_single_parent'] = '% With Single-Parent Households'\n",
    "    census_var_dict['percent_less_35k'] = '% of Households with Annual Income < $35k'\n",
    "    ndi_df['NDI Quartile'] = ndi_df['ndi_quantile'].map(ndi_map)\n",
    "\n",
    "    vars_to_plot = ['unemployment_rate', 'percent_poverty', 'no_health_insurance', \n",
    "                    'ed_percent_highschool', 'has_internet', 'percent_single_parent', \n",
    "                    'percent_less_35k']\n",
    "    fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8)) = plt.subplots(4, 2, figsize = (10,12))\n",
    "    ax_array = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8]\n",
    "\n",
    "\n",
    "    for i in range(0, len(vars_to_plot)):\n",
    "        if i == 1:\n",
    "            ndi_df.pivot(columns=\"NDI Quartile\", values=vars_to_plot[i]).plot.hist(bins=100, ax = ax_array[i])\n",
    "            ax_array[i].legend(loc = 'center left', bbox_to_anchor = (1, .5))\n",
    "        else:\n",
    "            ndi_df.pivot(columns=\"NDI Quartile\", values=vars_to_plot[i]).plot.hist(bins=100, ax = ax_array[i],\n",
    "                                                                                      legend = False)\n",
    "        xlab = census_var_dict[vars_to_plot[i]]\n",
    "        if '%' not in xlab:\n",
    "            xlab += ' (%)'\n",
    "        ax_array[i].set_xlabel(xlab)\n",
    "        ptitle = f'{xlab}'\n",
    "        ax_array[i].set_title(ptitle)\n",
    "        \n",
    "    plt.suptitle('Socioeconomic Status Variables by NDI Quartile', y = 1.01, x = 0.4)\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(data_io.output_plots/'ndi_comparisons.png', dpi = 400, bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('skipping NDI summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Census Stats with GFM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if NDI quartiles are in the dataset\n",
    "test = [i for i in df.columns.values if 'ndi_quantile' in i]\n",
    "merged_complete = True if len(test) > 0 else False\n",
    "print(merged_complete)\n",
    "#if NDI quartiles aren't already in GFM dataset, add them here:\n",
    "if merged_complete == False:\n",
    "\n",
    "    #Get the NDI quartiles--Note: Must run clustr.R to obtain them!\n",
    "    quarts = get_ndi_quartiles()\n",
    "    print(len(df))\n",
    "\n",
    "    #Merge with GFM dataset\n",
    "    df = pd.merge(df, quarts, how='left', on='state_county_fips_str')\n",
    "    print(len(df))\n",
    "    df.rename(columns={'county_x':'county_name', 'county_y':'county_fips_int'}, inplace=True)\n",
    "    print(df['county_fips_int'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the combined dataset hasn't been saved yet, set save to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if merge_ndi:\n",
    "    writer = pd.ExcelWriter(data_io.input_cleaned/'gfm'/'cancer_w_locs_and_text_features_census.xlsx',\n",
    "                           engine='xlsxwriter', options = EXCEL_OPTIONS)\n",
    "    df.to_excel(writer, encoding='utf-8', index= False)\n",
    "    writer.close()\n",
    "else:\n",
    "    print('df already saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndi_map = {1: '1 (least deprived)', \n",
    "           2: '2',\n",
    "           3: '3',\n",
    "           4: '4 (most deprived)'\n",
    "          }\n",
    "\n",
    "#convert NDI quartiles to factors (instead of integers)\n",
    "df['ndi_quantile_f'] = df['ndi_quantile'].map(ndi_map)\n",
    "vals = df['ndi_quantile_f'].value_counts()\n",
    "for v in vals.index:\n",
    "    print(v)\n",
    "    print(vals[v])\n",
    "    print(vals[v]/len(df))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.formula.api import glm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions for univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_percent(x, digits = 2):\n",
    "    if type(x) != str and pd.isnull(x)==False:\n",
    "        if digits == 2:\n",
    "            x = '{:.2%}'.format(x)\n",
    "        else:\n",
    "            x = '{:.3%}'.format(x)\n",
    "    return x\n",
    "\n",
    "def format_decimal(x, digits = 2):\n",
    "    if type(x) != str and type(x) != bool and pd.isnull(x)==False:\n",
    "        if digits == 2:\n",
    "            x = '{0:,.2f}'.format(x)\n",
    "        else:\n",
    "            x = '{0:,.3f}'.format(x)\n",
    "        return x\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def format_mean_sd(mean, sd):\n",
    "    mean = format_decimal(mean)\n",
    "    sd = format_decimal(sd)\n",
    "    \n",
    "    return f\"${mean} (${sd})\"\n",
    "    \n",
    "\n",
    "\n",
    "#Run an anova\n",
    "def compare_info_by_group(df, comp_cols, group_col):\n",
    "    for c in range(0, len(comp_cols)):\n",
    "        temp = df[~pd.isnull(df[comp_cols[c]])]\n",
    "        new = temp.groupby(group_col[c])\n",
    "        temp = temp[~pd.isnull(temp[group_col[c]])]\n",
    "        \n",
    "        mc = MultiComparison(temp[comp_cols[c]], temp[group_col[c]])\n",
    "        \n",
    "        result = mc.tukeyhsd()\n",
    "        mc_result = result.summary()\n",
    "        results_as_html = mc_result.as_html()\n",
    "        result_df = pd.read_html(results_as_html, header=0)[0]\n",
    "        result_df\n",
    "        return result_df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set columns for comparisons with labels for plotting\n",
    "mention_cols = ['brave', 'nice', 'thank', 'self_reliance', 'battle', 'tx_type', 'oop_type', 'insurance_type',\n",
    "               'ctype']\n",
    "\n",
    "groups = [m+'_is_mentioned' for m in mention_cols]\n",
    "\n",
    "#for labeling multivariate outputs\n",
    "pretty_groups = ['Bravery ', 'Warmth ','Gratitude ', 'Self-reliance ', 'Militaristic Metaphors ',\n",
    "                'Treatment ', 'OOP Cost ', 'Insurance ', 'Cancer Type ']\n",
    "#for labeling univariate outputs\n",
    "pretty_groups_univ = [i.rstrip() for i in pretty_groups]\n",
    "print(len(groups))\n",
    "print(len(pretty_groups))\n",
    "group_label_dict_univ = dict(zip(groups, pretty_groups_univ))\n",
    "group_label_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Chi-sq tests to compare mention of indicators by NDI quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "#Run pairwise comparisons for Chi-2 test\n",
    "def get_chi_2_post_hoc(df, groups):\n",
    "    all_results = pd.DataFrame()\n",
    "    for g in groups:\n",
    "        ct = pd.crosstab(df[g], df['ndi_quantile_f'])\n",
    "        ct.reset_index(inplace= True)\n",
    "        ct['var'] = g\n",
    "        ct.sort_values(by = g, inplace=True, ascending = False)\n",
    "        ct['var_value'] = ['True', 'False']\n",
    "        ct.drop(columns = [g], inplace=True)\n",
    "        comp_1_2 = ct[['1 (least deprived)', '2']]\n",
    "        comp_1_3 = ct[['1 (least deprived)', '3']]\n",
    "        comp_1_4 = ct[['1 (least deprived)', '4 (most deprived)']]\n",
    "        comp_2_3 = ct[['2', '3']]\n",
    "        comp_2_4 = ct[['2', '4 (most deprived)']]\n",
    "        comp_3_4 = ct[['3', '4 (most deprived)']]\n",
    "        \n",
    "        comp_arr = [comp_1_2, comp_1_3, comp_1_4, comp_2_3, comp_2_4, comp_3_4]\n",
    "        comp_strs = ['comp_1_2', 'comp_1_3', 'comp_1_4', 'comp_2_3', 'comp_2_4', 'comp_3_4']\n",
    "        for i in range(0, len(comp_arr)):\n",
    "            chi2, p, dof, ex = (chi2_contingency(comp_arr[i]))\n",
    "            #Bonferoni correction: \n",
    "            min_p = 0.05/len(comp_strs)\n",
    "            if p < min_p:\n",
    "                ct.loc[0, f'{comp_strs[i]}_sig_diff'] = True\n",
    "            else:\n",
    "                ct.loc[0, f'{comp_strs[i]}_sig_diff'] = False\n",
    "            ct.loc[0, f'chi_2_{comp_strs[i]}'] = chi2\n",
    "            ct.loc[0, f'dof_{comp_strs[i]}'] = dof\n",
    "            ct.loc[0, f'p_val_{comp_strs[i]}'] = p\n",
    "            \n",
    "        all_results = all_results.append(ct, ignore_index = True)\n",
    "        \n",
    "    return all_results\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Run omnibus chi_2 tests for NDI\n",
    "def calculate_chi_2_ndi(df, g, group_label_dict):\n",
    "    ndi_quants = ['1 (least deprived)', '2', '3', '4 (most deprived)']\n",
    "    ct = pd.crosstab(df[g], df['ndi_quantile_f'])\n",
    "    temp_idx = ct.index.astype(str).to_list()        \n",
    "    chi2, p, dof, ex = (chi2_contingency(ct))\n",
    "    ct.set_index(ct.index.astype(str)+f'_{g}', inplace=True)\n",
    "    \n",
    "    ct.loc[f'expected_{temp_idx[0]}_{g}', :] = ex[0, :]\n",
    "    \n",
    "    ct.loc[f'expected_{temp_idx[1]}_{g}', :] = ex[1, :]\n",
    "    \n",
    "    ct.loc[f'expected_less_obs_{g}', :] = ct.loc[f'expected_False_{g}', :] - ct.loc[f'False_{g}', :]\n",
    "    for nq in ndi_quants:\n",
    "        ct.loc[f'percent_mentioned_{g}', nq] = format_percent(ct.loc[f'True_{g}', nq] / (ct.loc[f'True_{g}', nq] + \n",
    "                                                                          ct.loc[f'False_{g}', nq]))\n",
    "        \n",
    "        ct.loc[f'expected_percent_mentioned_{g}', nq] = format_percent(ct.loc[f'expected_True_{g}', nq] / \n",
    "                                                                 (ct.loc[f'True_{g}', nq] + ct.loc[f'False_{g}', nq]))\n",
    "    idx_list = ct.index.to_list()\n",
    "    pretty_labels = []\n",
    "    for i in idx_list:\n",
    "        if 'expected' in i and 'less' not in i:\n",
    "            if 'expected_percent' in i:\n",
    "                pretty_labels.append('Expected Percent Mentioned')\n",
    "            elif 'False' in i:\n",
    "                pretty_labels.append('Expected False')\n",
    "            else:\n",
    "                pretty_labels.append('Expected True')\n",
    "        else:\n",
    "            if 'False' in i:\n",
    "                pretty_labels.append('Observed False')\n",
    "            elif 'True' in i:\n",
    "                pretty_labels.append('Observed True')\n",
    "            elif 'less' in i:\n",
    "                pretty_labels.append('Expected True - Observed True')\n",
    "            else:\n",
    "                pretty_labels.append(' ')\n",
    "\n",
    "    ct['var'] = group_label_dict[g]\n",
    "    ct['chi_2'] = chi2\n",
    "    ct['p'] = p\n",
    "    ct['df'] = dof\n",
    "    ct['pretty_labels'] = pretty_labels\n",
    "    \n",
    "    return ct\n",
    "        \n",
    "        \n",
    "ndi_quants = ['1 (least deprived)', '2', '3', '4 (most deprived)']\n",
    "temp_groups = groups.copy()\n",
    "#first, get the omnibus chi-square tests\n",
    "all_comps = pd.DataFrame()\n",
    "for g in temp_groups:\n",
    "    print(g)\n",
    "    #get the omnibus\n",
    "    temp_ct = calculate_chi_2_ndi(df, g, group_label_dict_univ)\n",
    "    all_comps = all_comps.append(temp_ct)\n",
    "    \n",
    "all_comps.reset_index(inplace=True)\n",
    "#next, get the post-hoc comparisons\n",
    "post_hoc = get_chi_2_post_hoc(df, groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_percent(x):\n",
    "    if type(x) == str:\n",
    "        x = x[0:-1]\n",
    "    return float(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function helps visualize X2 test results\n",
    "def plot_chi_2(chi_2, group):\n",
    "    ndi_quants = ['1 (least deprived)', '2', '3', '4 (most deprived)']\n",
    "    \n",
    "    temp_chi = chi_2[chi_2['index'].str.contains(group)]\n",
    "    temp_chi = temp_chi[temp_chi['index'].str.contains('percent')]\n",
    "    temp_chi = temp_chi.set_index('index')\n",
    "    temp_list = []\n",
    "    for nq in ndi_quants:\n",
    "        temp_list.append(unpack_percent(temp_chi.loc[f'percent_mentioned_{group}', nq]))\n",
    "    bars = temp_list\n",
    "    hline = unpack_percent(temp_chi.loc[f'expected_percent_mentioned_{group}', ndi_quants[0]])\n",
    "    title = temp_chi.loc[f'expected_percent_mentioned_{group}', 'var'] + ' is Mentioned:\\nObserved vs. Expected by NDI Quartile'\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(ndi_quants, bars, fc = '#A2D1CE', edgecolor = 'w')\n",
    "    ax.axhline(hline, linestyle = 'dashed', label = 'Overall % Mentioned', c = 'k')\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(bottom = 0, top = hline + 3)\n",
    "    ax.set_ylabel('% Mentioned')\n",
    "    ax.set_xlabel('NDI Quartile')\n",
    "    ax.set_yticklabels(['{:.0f}%'.format(x) for x in ax.get_yticks()])\n",
    "    plt.legend(loc = 'center left',  bbox_to_anchor = (1, .5))\n",
    "    plt.show()\n",
    "\n",
    "for g in temp_groups:\n",
    "    \n",
    "    plot_chi_2(all_comps, g)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the results if you want to\n",
    "save = False\n",
    "if save:\n",
    "    all_comps.to_csv(data_io.output_analysis/'chi2_tests_mention_by_NDI.csv')\n",
    "    post_hoc.to_csv(data_io.output_analysis/'chi2_post_hoc_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ndi_quantile_f.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run ANOVAs on NDI quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = ['raised_amnt', 'winsorized_goal', 'shares', 'num_contributors',\n",
    "              'percent_goal', 'avg_contribution']\n",
    "group_vals = np.unique(df['ndi_quantile_f'].values)\n",
    "#Iterate over all comparisons\n",
    "for c in comparisons:\n",
    "    mod = ols(f'{c} ~ ndi_quantile_f',\n",
    "                data=df).fit()\n",
    "                \n",
    "    aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "    aov_table.reset_index(inplace=True)\n",
    "    print(aov_table)\n",
    "    multicomp = compare_info_by_group(df, [c], ['ndi_quantile_f'])\n",
    "    \n",
    "    for i in range(0, len(aov_table)):\n",
    "        for col in aov_table.columns:\n",
    "            multicomp.loc[i, col] = aov_table.loc[i, col]\n",
    "            \n",
    "    multicomp.rename(columns={'index':'omnibus'}, inplace=True)\n",
    "    multicomp['outcome'] = c\n",
    "    \n",
    "    if c == comparisons[0]:\n",
    "        all_multicomp = multicomp.copy()\n",
    "    else:\n",
    "        all_multicomp = pd.concat((all_multicomp, multicomp), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results of ANOVA w post-hoc tests\n",
    "if save:\n",
    "    all_multicomp.to_csv(data_io.output_analysis/'anovas_by_NDI_quartile.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run comparisons in amount raised by potentially important confounding variables (year created, number of contributors, number of social media shares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare outcomes by year\n",
    "group_vals = np.unique(df['year'].values)\n",
    "\n",
    "for c in comparisons:\n",
    "    mod = ols(f'{c} ~ year',\n",
    "                data=df).fit()\n",
    "                \n",
    "    aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "    aov_table.reset_index(inplace=True)\n",
    "    print(aov_table)\n",
    "    multicomp = compare_info_by_group(df, [c], ['year'])\n",
    "    \n",
    "    for i in range(0, len(aov_table)):\n",
    "        for col in aov_table.columns:\n",
    "            multicomp.loc[i, col] = aov_table.loc[i, col]\n",
    "            \n",
    "    multicomp.rename(columns={'index':'omnibus'}, inplace=True)\n",
    "    multicomp['outcome'] = c\n",
    "    \n",
    "    if c == comparisons[0]:\n",
    "        mc_year = multicomp.copy()\n",
    "    else:\n",
    "        mc_year = pd.concat((mc_year, multicomp), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raised_amount_year_info = df.groupby(['year']).agg({'raised_amnt': ['count', 'mean', 'std']})\n",
    "#raised_amount_year_info.to_csv(data_io.output_analysis/'raised_amnt_by_year_desc.csv')\n",
    "\n",
    "\n",
    "    \n",
    "raised_amount_year_info.columns = ['count', 'mean', 'std']\n",
    "raised_amount_year_info['mean_sd_fmt'] = raised_amount_year_info.apply(lambda x: format_mean_sd(x['mean'],\n",
    "                                                                                               x['std']),\n",
    "                                                                      axis = 1)\n",
    "raised_amount_year_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    raised_amount_year_info.to_csv(data_io.output_analysis/'raised_amnt_by_year_desc.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results of ANOVA w post-hoc tests\n",
    "if save:\n",
    "    mc_year.to_csv(data_io.output_analysis/'anovas_by_campaign_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get spearman rank correlations between amount raised and potential confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_vars = ['num_contributors', 'shares', 'winsorized_goal']\n",
    "\n",
    "temp_df = df[['num_contributors', 'shares', 'winsorized_goal', 'raised_amnt']]\n",
    "corrs = temp_df.corr(method = 'spearman')\n",
    "corrs = corrs[['raised_amnt']]\n",
    "\n",
    "temp_df = df.dropna(subset=['raised_amnt'])\n",
    "\n",
    "for i in range(0, len(corr_vars)):\n",
    "    temp = temp_df.dropna(subset=[corr_vars[i]])\n",
    "    r, p = spearmanr(temp[corr_vars[i]], temp['raised_amnt'])\n",
    "    print(r, p)\n",
    "    corrs.loc[corr_vars[i], 'p_value'] = p\n",
    "if save:   \n",
    "    corrs.to_csv(data_io.output_analysis/'raised_amnt_confound_corrs.csv')\n",
    "corrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, run t-tests on binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "#From: https://campus.datacamp.com/courses/machine-learning-for-time-series-data-in-python/validating-and-inspecting-time-series-models?ex=12\n",
    "def bootstrap_interval(data, percentiles=(2.5, 97.5), n_boots=100):\n",
    "    \"\"\"Bootstrap a confidence interval for the mean of columns of a 2-D dataset.\"\"\"\n",
    "    # Create empty array to fill the results\n",
    "    bootstrap_means = np.zeros([n_boots, data.shape[-1]])\n",
    "    for ii in range(n_boots):\n",
    "        # Generate random indices for data *with* replacement, then take the sample mean\n",
    "        random_sample = resample(data)\n",
    "        bootstrap_means[ii] = random_sample.mean(axis=0)\n",
    "\n",
    "    # Compute the percentiles of choice for the bootstrapped means\n",
    "    percentiles = np.percentile(bootstrap_means, percentiles, axis=0)\n",
    "    return percentiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_groups(df, group_condition, group_col, group_labels,\n",
    "                       comparison_cols = ['raised_amnt', 'winsorized_goal',\n",
    "                                          'num_contributors', 'shares',\n",
    "                                         'percent_goal', 'avg_contribution']):\n",
    "    \n",
    "    result_df= pd.DataFrame()\n",
    "    g1 = df[df[group_col] == group_condition]\n",
    "    g2 = df[df[group_col]!= group_condition]\n",
    "    #Get t-test results for all comparison variables\n",
    "    for i in range(0, len(comparison_cols)):\n",
    "        #generate overall stats\n",
    "        result_df.loc[i, 'percent_mentioned'] = format_percent(len(g1)/len(df))\n",
    "        result_df.loc[i, 'overall_mean'] = df[comparison_cols[i]].mean()\n",
    "        result_df.loc[i, 'overall_std_err'] = df[comparison_cols[i]].sem()\n",
    "        result_df.loc[i, 'overall_sd'] = df[comparison_cols[i]].std()\n",
    "        result_df.loc[i, 'comparison_var'] = comparison_cols[i]\n",
    "        #Initialize temporary DF to store this comparison's results\n",
    "        comp_result_df = pd.DataFrame()\n",
    "        new_vnames = ['_g1', '_g2']\n",
    "        #Set up a list of DFs to iterate over\n",
    "        dfs = [g1, g2]\n",
    "        k = 0\n",
    "        for k in range(0, len(dfs)):\n",
    "            temp_df = dfs[k].copy()\n",
    "            comp_result_df.loc[0, \n",
    "                               f'n_missing{new_vnames[k]}'] = temp_df[comparison_cols[i]].isnull().sum()\n",
    "            temp_df.dropna(subset = [comparison_cols[i]], inplace = True)\n",
    "            comp_result_df.loc[0, f'n{new_vnames[k]}'] = len(temp_df)\n",
    "            comp_result_df.loc[0, f'mean{new_vnames[k]}'] = temp_df[comparison_cols[i]].mean()\n",
    "            comp_result_df.loc[0, f'fmtd_mean{new_vnames[k]}'] = format_decimal(temp_df[comparison_cols[i]].mean())\n",
    "            comp_result_df.loc[0, f'std_err{new_vnames[k]}'] = temp_df[comparison_cols[i]].sem()\n",
    "            comp_result_df.loc[0, f'sd{new_vnames[k]}'] = format_decimal(temp_df[comparison_cols[i]].std())\n",
    "            comp_result_df.loc[0, f'name{new_vnames[k]}'] = group_labels[k]\n",
    "            boot = bootstrap(temp_df[comparison_cols[i]].values)\n",
    "            c_intervals = bootstrap_interval(temp_df[comparison_cols[i]])\n",
    "            comp_result_df.loc[0, f'low_mean_ci{new_vnames[k]}'] = c_intervals[0, 0]\n",
    "            comp_result_df.loc[0, f'up_mean_ci{new_vnames[k]}'] = c_intervals[1, 0]\n",
    "            comp_result_df.loc[0, f'fmtd_mean_std{new_vnames[k]}'] = format_mean_sd(comp_result_df.loc[0, f'mean{new_vnames[k]}'],\n",
    "                                                                                   comp_result_df.loc[0, f'sd{new_vnames[k]}'])\n",
    "            #Replace old DF with temp DF to avoid null values when running t-test\n",
    "            dfs[k] = temp_df\n",
    "        \n",
    "        #Run the t-test\n",
    "        cm = sms.CompareMeans(sms.DescrStatsW(dfs[0][comparison_cols[i]]), \n",
    "                              sms.DescrStatsW(dfs[1][comparison_cols[i]]))\n",
    "        #Format result as pandas DF\n",
    "        comp_res = cm.summary()\n",
    "        comp_res = comp_res.as_html()\n",
    "        comp_res = pd.read_html(comp_res, header=0)[0]\n",
    "        #Add this comparison's results to the overall result dataframe\n",
    "        result_df.loc[i, 't_stat'] = comp_res.loc[0, 't']\n",
    "        result_df.loc[i, 'p_val'] = comp_res.loc[0, 'P>|t|']\n",
    "        result_df.loc[i, 'mean_diff'] = comp_res.loc[0, 'coef']\n",
    "        result_df.loc[i, 'lower_ci'] = comp_res.loc[0, '[0.025']\n",
    "        result_df.loc[i, 'upper_ci'] = comp_res.loc[0, '0.975]']\n",
    "        temp_colnames = comp_result_df.columns.to_list()\n",
    "        for t in temp_colnames:\n",
    "            result_df.loc[i, t] = comp_result_df.loc[0, t]\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def extract_varname(x):\n",
    "    if type(x) == str:\n",
    "        if ' is ' in x:\n",
    "            split_loc = x.find(' is ')\n",
    "            new_x = x[0:split_loc]\n",
    "        else:\n",
    "            new_x = x\n",
    "        new_x = new_x.replace(\" \", \"\\n\")\n",
    "        if '-' in new_x:\n",
    "            new_x = \"Self-\\nReliance\"\n",
    "        return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_label_dict = {}\n",
    "for i in range(0, len(groups)):\n",
    "    group_label_dict[groups[i]] = [pretty_groups[i] + 'is mentioned', pretty_groups[i] + 'is not mentioned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove NDI from groups temporarily since they can't be subjected to a t-test    \n",
    "temp_groups = ['self_reliance_is_mentioned', 'brave_is_mentioned', 'battle_is_mentioned', 'tx_type_is_mentioned',\n",
    "               'oop_type_is_mentioned', 'insurance_type_is_mentioned', 'ctype_is_mentioned', 'nice_is_mentioned',\n",
    "              'thank_is_mentioned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "i = 0\n",
    "for i in range(0, len(temp_groups)):\n",
    "    print(group_label_dict[temp_groups[i]])\n",
    "    temp = compare_two_groups(df, True, temp_groups[i], \n",
    "                                   group_label_dict[temp_groups[i]])\n",
    "    temp['var_name'] = temp_groups[i]\n",
    "    temp_fmtd_name = group_label_dict[temp_groups[i]][0]\n",
    "    temp['fmtd_var_name'] = extract_varname(temp_fmtd_name)\n",
    "    if i == 0:\n",
    "        t_tests = temp.copy()\n",
    "    else:\n",
    "        t_tests = pd.concat([t_tests, temp], ignore_index= True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results of t-test\n",
    "save = True\n",
    "if save:\n",
    "    t_tests.to_csv(data_io.output_analysis/'t_test_results.csv', encoding='utf-8', index=False)\n",
    "    #t_tests.to_csv('t_tests_new_method.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate more detailed descriptives on GFM vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define functions for descriptive stats\n",
    "def get_descriptive_stats(df):\n",
    "    descriptives = {}\n",
    "    cols_to_get = ['raised_amnt', 'winsorized_goal', 'num_contributors', 'avg_contribution',\n",
    "                  'percent_goal', 'likes', 'shares']\n",
    "    \n",
    "    years = np.unique(df['year'].dropna().values)\n",
    "    means = []\n",
    "    sds = []\n",
    "    medians = []\n",
    "    mins = []\n",
    "    maxes = []\n",
    "    missing = []\n",
    "    percent_missing = []\n",
    "    mean_sd_fmt = []\n",
    "    median_rg_fmt = []\n",
    "    pct_miss_num = []\n",
    "    \n",
    "    stats = ['mean', 'sd', 'median', 'min', 'max', 'missing', 'percent_missing', 'mean_sd_fmt',\n",
    "            'median_rg_fmt', 'pct_miss_num']\n",
    "    \n",
    "    for c in cols_to_get:\n",
    "        #print(c)\n",
    "        pct_miss_num.append(f\"{format_percent(df[c].isnull().sum()/len(df))} ({format_decimal(df[c].isnull().sum())})\")\n",
    "        missing.append(format_decimal(df[c].isnull().sum()))\n",
    "        percent_missing.append(format_percent(df[c].isnull().sum()/len(df)))\n",
    "        if 'percent' not in c:\n",
    "            means.append(format_decimal(df[c].mean()))\n",
    "            sds.append(format_decimal(df[c].std()))\n",
    "            medians.append(format_decimal(df[c].median()))\n",
    "            mins.append(format_decimal(df[c].min()))\n",
    "            maxes.append(format_decimal(df[c].max()))\n",
    "            \n",
    "            if 'raised' in c or 'winsor'in c or 'avg_con' in c: \n",
    "                mean_sd_fmt.append(f\"${format_decimal(df[c].mean())} (${format_decimal(df[c].std())})\")\n",
    "                median_rg_fmt.append(f\"${format_decimal(df[c].median())} (${format_decimal(df[c].min())} - ${format_decimal(df[c].max())})\")\n",
    "            else:\n",
    "                mean_sd_fmt.append(f\"{format_decimal(df[c].mean())} ({format_decimal(df[c].std())})\")\n",
    "                median_rg_fmt.append(f\"{format_decimal(df[c].median())} ({format_decimal(df[c].min())} - {format_decimal(df[c].max())})\")\n",
    "            \n",
    "        else:\n",
    "            means.append(format_percent(df[c].mean()))\n",
    "            sds.append(format_percent(df[c].std()))\n",
    "            medians.append(format_percent(df[c].median()))\n",
    "            mins.append(format_percent(df[c].min()))\n",
    "            maxes.append(format_percent(df[c].max()))\n",
    "            mean_sd_fmt.append(f\"{format_percent(df[c].mean())} ({format_percent(df[c].std())})\")\n",
    "            median_rg_fmt.append(f\"{format_percent(df[c].median())} ({format_percent(df[c].min())} - {format_percent(df[c].max())})\")\n",
    "    \n",
    "    new = pd.DataFrame(columns=cols_to_get, index=stats, data = [means, sds, medians, mins, \n",
    "                                                                 maxes, missing, percent_missing,\n",
    "                                                                    mean_sd_fmt, median_rg_fmt, pct_miss_num])\n",
    "    \n",
    "    #Non-numeric variables\n",
    "    non_num = ['year', 'ndi_quantile_f', 'brave_is_mentioned', 'nice_is_mentioned', 'thank_is_mentioned', \n",
    "               'self_reliance_is_mentioned', \n",
    "                 'battle_is_mentioned', 'ctype_is_mentioned', 'oop_type_is_mentioned', 'insurance_type_is_mentioned', \n",
    "                 'tx_type_is_mentioned', 'met_goal']\n",
    "    for n in non_num:\n",
    "        val_counts = df[n].value_counts()\n",
    "        for i in val_counts.index:\n",
    "            index = str(i) +'_'+n\n",
    "            new.loc['count', index] = val_counts[i]\n",
    "            new.loc['percent', index] = format_percent(val_counts[i]/len(df))\n",
    "            new.loc['fmt_count_pct', index] = f\"{new.loc['percent', index]} ({val_counts[i]})\"\n",
    "    \n",
    "    \n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = get_descriptive_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    desc.to_csv(data_io.output_analysis/'gfm_campaign_descriptive_characteristics.csv', \n",
    "                encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in df with name mappings for formatting \n",
    "RE_FMT = pd.read_csv(data_io.input_cleaned/'gfm'/'rename_reg_outputs.csv')\n",
    "def create_ref_vals(re_fmt):\n",
    "    for i in re_fmt.index:\n",
    "        if pd.isnull(re_fmt.loc[i, 'fmt_ref']) == False:\n",
    "            re_fmt.loc[i, 'varname_w_ref'] = str(re_fmt.loc[i, 'fmt_varname_w_val']) + '\\n' + re_fmt.loc[i, 'fmt_ref']\n",
    "    return re_fmt\n",
    "\n",
    "RE_FMT = create_ref_vals(RE_FMT)\n",
    "\n",
    "#Functions to handle results of multivariate regression\n",
    "def frmt_coef_and_se(coef, se):\n",
    "    new_coef = format_decimal(coef, digits = 3)\n",
    "    new_se = format_decimal(se, digits = 3)\n",
    "    return f\"{new_coef} ({new_se})\"\n",
    "\n",
    "def frmt_pct_and_ci(pct, ci_lower, ci_upper):\n",
    "    return f\"{pct}\\n({ci_lower}, {ci_upper})\"\n",
    "\n",
    "#Reformats the regression outputs for easy plotting/reporting\n",
    "def parse_results(result):\n",
    "    results_summary = result.summary()\n",
    "    #convert summary object to dataframe\n",
    "    results_as_html = results_summary.tables[1].as_html()\n",
    "    result_df = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "    result_df.columns = ['coef', 'std err', 'z', 'p_value', 'coef_low_ci', 'coef_up_ci']\n",
    "    result_df['percent_diff'] = np.exp((result_df['coef']))-1\n",
    "    result_df['percent_diff_lower'] = np.exp((result_df['coef_low_ci']))-1\n",
    "    result_df['percent_diff_upper'] = np.exp((result_df['coef_up_ci']))-1\n",
    "    \n",
    "    result_df['percent_diff_frmt'] = result_df.percent_diff.apply(format_percent)\n",
    "    result_df['percent_diff_lower_frmt'] = result_df.percent_diff_lower.apply(format_percent)\n",
    "    result_df['percent_diff_upper_frmt'] = result_df.percent_diff_upper.apply(format_percent)\n",
    "    \n",
    "    result_df['fmt_coef'] = result_df.apply(lambda x: frmt_coef_and_se(x['coef'], x['std err']),\n",
    "                                           axis = 1)\n",
    "    result_df['pct_ci_frmt'] = result_df.apply(lambda x: frmt_pct_and_ci(x['percent_diff_frmt'],\n",
    "                                                                       x['percent_diff_lower_frmt'],\n",
    "                                                                       x['percent_diff_upper_frmt']),\n",
    "                                              axis = 1)\n",
    "    \n",
    "    result_df.reset_index(inplace=True)\n",
    "    result_df.rename(columns={'index':'variable'}, inplace=True)\n",
    "    temp_quantile_dict = {'ndi_quantile_f[T.2]': '2',\n",
    "                      'ndi_quantile_f[T.3]': '3',\n",
    "                      'ndi_quantile_f[T.4 (most deprived)]': '4 (most deprived)'}\n",
    "    \n",
    "    var_names = result_df['variable'].to_list()\n",
    "    result_df['var_val'] = ''\n",
    "    for i in range(0, len(var_names)):\n",
    "        if 'T.True' in var_names[i]:\n",
    "            var_names[i] = var_names[i].replace('[T.True]', '')\n",
    "            result_df.loc[i, 'var_val'] = 'True'\n",
    "        elif 'quantile' in var_names[i]:\n",
    "            result_df.loc[i, 'var_val'] = temp_quantile_dict[var_names[i]]\n",
    "            var_names[i] = 'ndi_quantile_f'\n",
    "\n",
    "\n",
    "    result_df['var_name'] = var_names\n",
    "\n",
    "    result_df['var_name_w_val'] = result_df['var_name'] + result_df['var_val'].astype(str)\n",
    "    \n",
    "    result_df = pd.merge(result_df, RE_FMT, how = 'left', left_on = 'var_name_w_val',\n",
    "                        right_on = 'orig_varname_w_val')\n",
    "    \n",
    "    \n",
    "    return result_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the GLM\n",
    "df['year_f'] = df['year'].astype(str)\n",
    "\n",
    "\n",
    "raised_amnt = glm(formula = ('log_raised_amnt ~ ndi_quantile_f+ ctype_is_mentioned + brave_is_mentioned + '+\n",
    "                            'winsorized_goal + shares + nice_is_mentioned + thank_is_mentioned+'+\n",
    "                            'num_contributors + insurance_type_is_mentioned + self_reliance_is_mentioned +'+\n",
    "                            'battle_is_mentioned + oop_type_is_mentioned + tx_type_is_mentioned + year_f'),\n",
    "                  data = df, family = sm.families.Gaussian())\n",
    "result = raised_amnt.fit()\n",
    "results_summary = result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format GLM results\n",
    "reg_results = parse_results(result)\n",
    "reg_results.loc[pd.isnull(reg_results['order']), 'order'] = 15\n",
    "reg_results = reg_results.sort_values(by = 'order')\n",
    "#save the results\n",
    "#reg_results.to_csv(data_io.output_analysis/'glm_percent_change_formatted_v1.csv', index=False)\n",
    "reg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    reg_results.to_csv(data_io.output_analysis/'glm_percent_change.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.statisticshowto.datasciencecentral.com/wald-test/\n",
    "wald = result.wald_test_terms()\n",
    "wald.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add NDI quantiles back into the groups\n",
    "if 'ndi_quantile_f' not in groups:\n",
    "    groups.append('ndi_quantile_f')\n",
    "    pretty_groups.extend(['NDI Quartile '])\n",
    "else:\n",
    "    print('ndi already in groups')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results of the multivariate regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#add significance/p-val indicators\n",
    "def assign_significance(percent, sig):\n",
    "    if pd.isnull(percent) == False:\n",
    "        if sig <= 0.001:\n",
    "            return percent + '***'\n",
    "        elif sig <= 0.01:\n",
    "            return percent + '**'\n",
    "        elif sig <= 0.05:\n",
    "            return percent + '*'\n",
    "        else:\n",
    "            return percent\n",
    "def set_aspect_ratio(ax,ratio=0.5):\n",
    "    xleft, xright = ax.get_xlim()\n",
    "    ybottom, ytop = ax.get_ylim()\n",
    "    # the abs method is used to make sure that all numbers are positive\n",
    "    # because x and y axis of an axes maybe inversed.\n",
    "    ax.set_aspect(abs((xright-xleft)/(ybottom-ytop))*ratio)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up plot for text characteristics\n",
    "temp_means = t_tests.drop(columns = ['p_val'])\n",
    "temp_means = temp_means[temp_means['comparison_var'] == 'raised_amnt']\n",
    "merged = pd.merge(temp_means, reg_results, on = 'var_name')\n",
    "merged['labels'] = merged.apply(lambda x: assign_significance(x['percent_diff_frmt'],\n",
    "                                                        x['p_value']),\n",
    "                                 axis = 1)\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.groupby('ndi_quantile_f').apply(lambda x: bootstrap_interval(x['raised_amnt']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Set up plot for NDI \n",
    "ndi_metrics = df.groupby('ndi_quantile_f').agg({'raised_amnt': ['mean', 'std', 'sem']}).reset_index()\n",
    "ndi_metrics.columns = ['var_val', 'mean_amnt_raised', 'std_amnt_raised', 'std_err_amnt_raised']\n",
    "ndi_metrics['var_name'] = 'ndi_quantile_f'\n",
    "for i in range(0, len(ndi_metrics)):\n",
    "    temp_df = df[df['ndi_quantile_f'] == ndi_metrics.loc[i, 'var_val']]\n",
    "    temp_df = temp_df.dropna(subset=['raised_amnt'])\n",
    "    temp_ci = bootstrap_interval(temp_df['raised_amnt'])\n",
    "    ndi_metrics.loc[i, 'lower_mean_ci'] = temp_ci[0, 0]\n",
    "    ndi_metrics.loc[i, 'upper_mean_ci'] = temp_ci[1, 0]\n",
    "    print(ndi_metrics)\n",
    "    \n",
    "temp_ndi = pd.merge(ndi_metrics, reg_results, on = ['var_name', 'var_val'])\n",
    "add_idx = len(temp_ndi)\n",
    "for c in ndi_metrics.columns:\n",
    "    temp_ndi.loc[add_idx, c] = ndi_metrics.loc[0, c]\n",
    "temp_ndi['fmt_var_val'] = temp_ndi['var_val'].apply(extract_varname)\n",
    "temp_ndi.sort_values(by = ['mean_amnt_raised'], ascending = False, inplace=True)\n",
    "temp_ndi['labels'] = temp_ndi.apply(lambda x: assign_significance(x['percent_diff_frmt'],\n",
    "                                                                    x['p_value']),\n",
    "                                    axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "if save:\n",
    "    merged.to_csv(data_io.output_analysis/'text_mention_outputs_for_plots.csv')\n",
    "    temp_ndi.to_csv(data_io.output_analysis/'ndi_outputs_for_plots.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax2, ax1) = plt.subplots(nrows = 2, figsize = (15, 15))\n",
    "#Set top axis\n",
    "temp_ndi['fmt_var_val'] = ['NDI: 1\\n(least deprived)', 'NDI: 2',\n",
    "                          'NDI: 3', 'NDI: 4\\n(most deprived)']\n",
    "#compute error bars\n",
    "temp_ndi['lower_errors'] = temp_ndi['mean_amnt_raised'] - temp_ndi['lower_mean_ci']\n",
    "temp_ndi['upper_errors'] = temp_ndi['upper_mean_ci'] - temp_ndi['mean_amnt_raised']\n",
    "\n",
    "ax2.bar(temp_ndi['fmt_var_val'], temp_ndi['mean_amnt_raised'],\n",
    "       yerr = [temp_ndi['lower_errors'], temp_ndi['upper_errors']],\n",
    "       facecolor='c', ec = 'k', width = 0.3)\n",
    "\n",
    "ax2.set_ylabel('Mean Amount Raised (USD)')\n",
    "rects = ax2.patches\n",
    "rect_labels = ['Ref.']\n",
    "rect_labels.extend(temp_ndi['labels'].dropna().to_list())\n",
    "for rect, label in zip(rects, rect_labels):\n",
    "    width = rect.get_width()\n",
    "    height = rect.get_height()\n",
    "    \n",
    "    y = rect.get_y() + rect.get_height() + 200\n",
    "    x = rect.get_x() + 0.15\n",
    "    ax2.text(x, y, label,\n",
    "            ha='center', va='bottom')\n",
    "    \n",
    "ax2.set_ylim(0, max(temp_ndi['mean_amnt_raised'])+500)\n",
    "ax2.set_xlim(-.5, 3.5)\n",
    "ax2.text(-0.85, max(temp_ndi['mean_amnt_raised'])+500, 'A.', \n",
    "         ha = 'left', va = 'top', size = 20)\n",
    "set_aspect_ratio(ax2)\n",
    "\n",
    "#Set the bottom axis\n",
    "x_vals = np.arange(0, len(merged))\n",
    "\n",
    "merged['lower_error_bar_g1'] = merged['mean_g1'] - merged['low_mean_ci_g1']\n",
    "merged['upper_error_bar_g1'] = merged['up_mean_ci_g1'] - merged['mean_g1']\n",
    "width = 0.25\n",
    "new_xvals_g1 = [x - width/2 for x in x_vals]\n",
    "new_xvals_g2 = [x + width/2 for x in x_vals]\n",
    "ax1.bar(new_xvals_g1, merged['mean_g1'], width, \n",
    "                    yerr = [merged['lower_error_bar_g1'], merged['upper_error_bar_g1']],\n",
    "                    label = 'Text Feature Mentioned',\n",
    "                    facecolor = 'seagreen',\n",
    "                    ec = 'k')\n",
    "\n",
    "rects = ax1.patches\n",
    "rect_labels = merged['labels'].dropna().to_list()\n",
    "for rect, label in zip(rects, rect_labels):\n",
    "    width = rect.get_width()\n",
    "    height = rect.get_height()\n",
    "    \n",
    "    y = rect.get_y() + rect.get_height() + 300\n",
    "    x = rect.get_x() + 0.15\n",
    "    ax1.text(x, y, label,\n",
    "            ha='center', va='bottom')\n",
    "\n",
    "merged['lower_error_bar_g2'] = merged['mean_g2'] - merged['low_mean_ci_g2']\n",
    "merged['upper_error_bar_g2'] = merged['up_mean_ci_g2'] - merged['mean_g2']    \n",
    "\n",
    "ax1.bar(new_xvals_g2, merged['mean_g2'], \n",
    "        width, label = 'Text Feature Not Mentioned',\n",
    "        yerr = [merged['lower_error_bar_g2'], merged['upper_error_bar_g2']],\n",
    "        facecolor = 'lightgrey',\n",
    "        edgecolor = 'k')\n",
    "    \n",
    "ax1.set_xticks(x_vals)\n",
    "ax1.set_xticklabels(merged['fmtd_var_name'])\n",
    "\n",
    "ax1.set_ylim(bottom = 0, top = max(merged['mean_g1'])+1400)\n",
    "ax1.set_ylabel('Mean Amount Raised (USD)')\n",
    "ax1.text(-1.5, max(merged['mean_g1'])+1400, 'B.', \n",
    "         ha = 'left', va = 'top', size = 20)\n",
    "set_aspect_ratio(ax1)\n",
    "ax1.legend(loc = 'upper center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(data_io.output_plots/'all_reg_outputs.png', dpi = 400, bbox_inches = 'tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
